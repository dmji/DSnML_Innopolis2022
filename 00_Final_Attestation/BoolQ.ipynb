{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "__COLAB_ACTIVE = False\n",
        "__POOL_MODEL = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Проект 3. Решить задачу DaNetQA / BoolQ\n",
        "\n",
        "Можно решить как задачу для русского, так и для английского.\n",
        "\n",
        "Либо провести эксперименты с многоязычной моделью\n",
        "\n",
        "https://russiansuperglue.com/ru/tasks/task_info/DaNetQA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Описание\n",
        "Причинно-следственная связь, логический вывод, Natural Language Inference\n",
        "\n",
        "DaNetQA - это набор да/нет вопросов с ответами и фрагментом текста, содержащим ответ. Все вопросы были написаны авторами без каких-либо искусственных ограничений.\n",
        "\n",
        "Каждый пример представляет собой триплет (вопрос, фрагмент текста, ответ) с заголовком страницы в качестве необязательного дополнительного контекста.\n",
        "\n",
        "Настройка классификации текстовых пар аналогична существующим задачам логического вывода (NLI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Тип задачи\n",
        "Логика, Commonsense, Знания о мире. Бинарная классификация: true/false"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Root path: 'd:\\New folder\\New folder\\DSnML_Innopolis2022\\00_Final_Attestation'\n",
            "Dataset path: d:\\New folder\\New folder\\DSnML_Innopolis2022\\00_Final_Attestation\\DaNetQA\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "\n",
        "base_path = os.path.abspath('')\n",
        "if __COLAB_ACTIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base_path = os.path.join(base_path, 'drive/MyDrive/DSnML_Innopolis2022')\n",
        "\n",
        "print(f\"Root path: '{base_path}'\")\n",
        "\n",
        "trainPartNameRaw = 'raw_train'\n",
        "testPartNameRaw = 'raw_val'\n",
        "validatePartNameRaw = 'raw_test'\n",
        "\n",
        "trainPartName = 'train_v1'\n",
        "testPartName = 'val_v1'\n",
        "validatePartName = 'test_v1'\n",
        "parts = [trainPartName, testPartName]\n",
        "data_path = os.path.join(base_path, 'DaNetQA')\n",
        "print(f\"Dataset path: {data_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fileNameData(s):\n",
        "    return f\"{os.path.join(data_path, s)}.jsonl\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\leysh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loadJSONL(path, name):\n",
        "    df = pd.read_json(path, lines=True)\n",
        "    print(name)\n",
        "    display(df.head())\n",
        "    if (df.columns.values == 'label').any():\n",
        "        s = np.unique(df['label'].to_numpy(), return_counts=True)[1]\n",
        "        print(f\"True answer: {s[1]}\")\n",
        "        print(f\"False answer: {s[0]}\")\n",
        "        print(\"\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>passage</th>\n",
              "      <th>label</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Вднх - это выставочный центр?</td>\n",
              "      <td>«Вы́ставочный центр» — станция Московского мон...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Вднх - это выставочный центр?</td>\n",
              "      <td>Вы́ставка достиже́ний наро́дного хозя́йства  ,...</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Был ли джиган в black star?</td>\n",
              "      <td>Вместе с этим треком они выступили на церемони...</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Xiaomi конкурент apple?</td>\n",
              "      <td>Xiaomi — китайская компания, основанная в 2010...</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Был ли автомат калашникова в вов?</td>\n",
              "      <td>Отметив некоторые недостатки и в целом удачную...</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            question  \\\n",
              "0      Вднх - это выставочный центр?   \n",
              "1      Вднх - это выставочный центр?   \n",
              "2        Был ли джиган в black star?   \n",
              "3            Xiaomi конкурент apple?   \n",
              "4  Был ли автомат калашникова в вов?   \n",
              "\n",
              "                                             passage  label  idx  \n",
              "0  «Вы́ставочный центр» — станция Московского мон...   True    0  \n",
              "1  Вы́ставка достиже́ний наро́дного хозя́йства  ,...   True    1  \n",
              "2  Вместе с этим треком они выступили на церемони...   True    2  \n",
              "3  Xiaomi — китайская компания, основанная в 2010...   True    3  \n",
              "4  Отметив некоторые недостатки и в целом удачную...  False    4  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True answer: 1061\n",
            "False answer: 688\n",
            "\n",
            "Test set:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>passage</th>\n",
              "      <th>label</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>вода марсе ?</td>\n",
              "      <td>гидросфера марса — это совокупность водных зап...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>состоит англия евросоюзе ?</td>\n",
              "      <td>полночь 31 января 1 февраля 2020 года централь...</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>деиствительно ссср адвокатов ?</td>\n",
              "      <td>семен львович ария — советскии россиискии юрис...</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>чума оране ?</td>\n",
              "      <td>чума — это абсурд , осмысливается форма сущест...</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>кетчуп читосе ?</td>\n",
              "      <td>текущии каталог продукции размещен саите произ...</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         question  \\\n",
              "0                    вода марсе ?   \n",
              "1      состоит англия евросоюзе ?   \n",
              "2  деиствительно ссср адвокатов ?   \n",
              "3                    чума оране ?   \n",
              "4                 кетчуп читосе ?   \n",
              "\n",
              "                                             passage  label  idx  \n",
              "0  гидросфера марса — это совокупность водных зап...   True    0  \n",
              "1  полночь 31 января 1 февраля 2020 года централь...  False    1  \n",
              "2  семен львович ария — советскии россиискии юрис...  False    2  \n",
              "3  чума — это абсурд , осмысливается форма сущест...   True    3  \n",
              "4  текущии каталог продукции размещен саите произ...   True    4  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True answer: 412\n",
            "False answer: 409\n",
            "\n",
            "Validation set\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>passage</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Полезна ли ртуть с градусника?</td>\n",
              "      <td>Отравления ртутью  — расстройства здоровья, св...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Являются ли сапрофаги хищниками?</td>\n",
              "      <td>Фауна лесных почв — совокупность видов животны...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Водятся ли в индии крокодилы?</td>\n",
              "      <td>Болотный крокодил, или магер  — пресмыкающееся...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Есть ли в батате крахмал?</td>\n",
              "      <td>Клубневидно вздутые корни  весят до 15 кг, сод...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Был ли человек в железной маске?</td>\n",
              "      <td>Остров Сент-Маргерит  — крупнейший из Лерински...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           question  \\\n",
              "0    Полезна ли ртуть с градусника?   \n",
              "1  Являются ли сапрофаги хищниками?   \n",
              "2     Водятся ли в индии крокодилы?   \n",
              "3         Есть ли в батате крахмал?   \n",
              "4  Был ли человек в железной маске?   \n",
              "\n",
              "                                             passage  idx  \n",
              "0  Отравления ртутью  — расстройства здоровья, св...    0  \n",
              "1  Фауна лесных почв — совокупность видов животны...    1  \n",
              "2  Болотный крокодил, или магер  — пресмыкающееся...    2  \n",
              "3  Клубневидно вздутые корни  весят до 15 кг, сод...    3  \n",
              "4  Остров Сент-Маргерит  — крупнейший из Лерински...    4  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_train = loadJSONL(fileNameData(trainPartNameRaw), \"Train set\")\n",
        "df_test = loadJSONL(fileNameData(testPartNameRaw), \"Test set:\")\n",
        "df_validation = loadJSONL(fileNameData(validatePartNameRaw), \"Validation set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Очистка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataCleaner:\n",
        "    def __init__(self) -> None:\n",
        "        self.flag_verbose = True\n",
        "\n",
        "        self.stop_words = stopwords.words('russian')\n",
        "        self.stemmer = SnowballStemmer('russian')\n",
        "\n",
        "        self.count_removed_symbols = dict()\n",
        "        self.count_removed_words = dict()\n",
        "\n",
        "        self.count_replaced_symbols = dict()\n",
        "        self.dict_replaced_symbols = dict()\n",
        "\n",
        "        self.count_replaced_words = dict()\n",
        "        self.dict_replaced_words = dict()\n",
        "\n",
        "        self.char_to_remove = ['«', '»', '—', ',', '.', '-', '/', ':', '!', \"?\", \"(\", \")\", \"{\", \"}\", \"[\", \"]\", \"@\", \"#\", \"$\", \"%\", \"^\", \"&\", \"*\", \"=\", \"|\", \"\\\\\", \">\", \"<\"]\n",
        "        self.char_to_replace = [['ё', 'е']]\n",
        "\n",
        "    # функция подсчета количества измененных слов\n",
        "    def addReplacedWord(self, s_from, s_to = ' '):\n",
        "        if not self.count_replaced_words.keys().__contains__(s_from):\n",
        "            self.count_replaced_words[s_from] = 0\n",
        "        self.count_replaced_words[s_from] += 1\n",
        "        self.dict_replaced_words[s_from] = s_to\n",
        "\n",
        "    # функция подсчета количества удаленных слов\n",
        "    def addRemovedWord(self, w):\n",
        "        if w == ' ':\n",
        "            if not self.count_removed_symbols.keys().__contains__(w):\n",
        "                self.count_removed_symbols[w] = 0\n",
        "            self.count_removed_symbols[w] += 1\n",
        "\n",
        "    # функция подсчета количества удаленных символов\n",
        "    def addReplacedSymbol(self, s_from, s_to = ' '):\n",
        "        if s_to == ' ':\n",
        "            if not self.count_removed_symbols.keys().__contains__(s_from):\n",
        "                self.count_removed_symbols[s_from] = 0\n",
        "            self.count_removed_symbols[s_from] += 1\n",
        "        else:\n",
        "            if not self.count_replaced_symbols.keys().__contains__(s_from):\n",
        "                self.count_replaced_symbols[s_from] = 0\n",
        "            self.count_replaced_symbols[s_from] += 1\n",
        "            self.dict_replaced_symbols[s_from] = s_to\n",
        "\n",
        "    # удаление знаков ударения и прочих символов unicode\n",
        "    def unicodeToAscii(self, s):\n",
        "        tmp = []\n",
        "        for c in unicodedata.normalize('NFD', s):\n",
        "            if unicodedata.category(c) != 'Mn':\n",
        "                tmp.append(c)\n",
        "            else:\n",
        "                self.addReplacedSymbol(c)\n",
        "        return ''.join(tmp)\n",
        "\n",
        "    # если нужно удалить, то заменяем на пробел чтоб не потерят разделения слов\n",
        "    def replaceChar(self, s):\n",
        "        tmp = []\n",
        "        for i, c in enumerate(s):\n",
        "            if self.char_to_remove.__contains__(c):\n",
        "                self.addReplacedSymbol(c, s[i])\n",
        "                tmp.append(' ')\n",
        "            else:\n",
        "                tmp.append(c)\n",
        "        s = \"\".join(tmp)\n",
        "\n",
        "        for s_from, s_to in self.char_to_replace:\n",
        "            if c == s_from:\n",
        "                s[i] = s_to\n",
        "                self.addReplacedSymbol(s_from, s_to)\n",
        "        return s\n",
        "\n",
        "    # удаляем лишние пробелы\n",
        "    def trimSpaces(self, s):\n",
        "        while s.__contains__('  '):\n",
        "            s = s.replace('  ', ' ')\n",
        "        s = s.strip()\n",
        "        return s\n",
        "\n",
        "    # удаляем слва из stopwords\n",
        "    def removeStopWords(self, s):\n",
        "        tmp = []\n",
        "        for word in word_tokenize(s):\n",
        "            if word not in self.stop_words:\n",
        "                tmp.append(word)\n",
        "            else:\n",
        "                self.addRemovedWord(word)\n",
        "        return \" \".join(tmp)\n",
        "\n",
        "    # удаляем слва из stopwords\n",
        "    def StemmWords(self, s):\n",
        "        tmp = []\n",
        "        for word in word_tokenize(s):\n",
        "            wordStemmed = self.stemmer.stem(word)\n",
        "            tmp.append(wordStemmed)\n",
        "            if word != wordStemmed:\n",
        "                self.addReplacedWord(word, wordStemmed)\n",
        "        return \" \".join(tmp)\n",
        "\n",
        "    def clean(self, df, column):\n",
        "        for i in range(len(df)):\n",
        "            df[column][i] = self.unicodeToAscii(df[column][i])\n",
        "            df[column][i] = df[column][i].lower()\n",
        "            df[column][i] = self.replaceChar(df[column][i])\n",
        "            df[column][i] = self.removeStopWords(df[column][i])\n",
        "            df[column][i] = self.StemmWords(df[column][i])\n",
        "            df[column][i] = self.trimSpaces(df[column][i])\n",
        "        return df\n",
        "\n",
        "    # прокси для выключения вывода на экран summary\n",
        "    def print(self, vals):\n",
        "        if self.flag_verbose == True:\n",
        "            print(vals)\n",
        "\n",
        "    # прокси для выключения вывода на экран summary\n",
        "    def display(self, vals):\n",
        "            if self.flag_verbose == True:\n",
        "                display(vals)\n",
        "\n",
        "    # сбор лога в dataframe, опциональный вывод на экран \n",
        "    def summary(self, verbose = True):\n",
        "        self.flag_verbose = verbose\n",
        "        dfs = []\n",
        "\n",
        "        self.print(\"===================================\")\n",
        "        self.print(\"===        Removed Chars        ===\")\n",
        "        self.print(\"===================================\")\n",
        "        \n",
        "        cols = [\"symbol\", \"count_removed\"]\n",
        "        dfRemoved = pd.DataFrame(columns=cols)\n",
        "        for c in self.count_removed_symbols:\n",
        "            current_df = pd.DataFrame([[c, self.count_removed_symbols[c]]], columns=cols) \n",
        "            dfRemoved = pd.concat([dfRemoved, current_df], ignore_index=True)\n",
        "        self.display(dfRemoved)\n",
        "        dfs.append(['Removed Chars', dfRemoved])\n",
        "\n",
        "        self.print(\"===================================\")\n",
        "        self.print(\"===        Removed Words        ===\")\n",
        "        self.print(\"===================================\")\n",
        "        \n",
        "        cols = [\"word\", \"count_removed\"]\n",
        "        dfRemoved = pd.DataFrame(columns=cols)\n",
        "        for c in self.count_removed_words:\n",
        "            current_df = pd.DataFrame([[c, self.count_removed_words[c]]], columns=cols) \n",
        "            dfRemoved = pd.concat([dfRemoved, current_df], ignore_index=True)\n",
        "        self.display(dfRemoved)\n",
        "        dfs.append(['Removed Words', dfRemoved])\n",
        "\n",
        "        self.print(\"===================================\")\n",
        "        self.print(\"===        Replaced Chars       ===\")\n",
        "        self.print(\"===================================\")\n",
        "        \n",
        "        cols = [\"symbol_from\", \"symbol_to\", \"count_replaced\"]\n",
        "        dfRemoved = pd.DataFrame(columns=cols)\n",
        "        for c in self.dict_replaced_symbols:\n",
        "            current_df = pd.DataFrame([[ c, self.dict_replaced_symbols[c], self.count_replaced_symbols[c]]], columns=cols) \n",
        "            dfRemoved = pd.concat([dfRemoved, current_df], ignore_index=True)\n",
        "        self.display(dfRemoved)\n",
        "        dfs.append(['Replaced Chars', dfRemoved])\n",
        "\n",
        "        self.print(\"===================================\")\n",
        "        self.print(\"===        Stemmed Words        ===\")\n",
        "        self.print(\"===================================\")\n",
        "        \n",
        "        cols = [\"word_from\", \"word_to\", \"count_replaced\"]\n",
        "        dfRemoved = pd.DataFrame(columns=cols)\n",
        "        for c in self.dict_replaced_words:\n",
        "            current_df = pd.DataFrame([[ c, self.dict_replaced_words[c], self.count_replaced_words[c]]], columns=cols) \n",
        "            dfRemoved = pd.concat([dfRemoved, current_df], ignore_index=True)\n",
        "        self.display(dfRemoved)\n",
        "        dfs.append(['Stemmed Words', dfRemoved])\n",
        "\n",
        "        return dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\leysh\\AppData\\Local\\Temp\\ipykernel_2064\\3611868607.py:102: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column][i] = self.unicodeToAscii(df[column][i])\n",
            "C:\\Users\\leysh\\AppData\\Local\\Temp\\ipykernel_2064\\3611868607.py:103: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column][i] = df[column][i].lower()\n",
            "C:\\Users\\leysh\\AppData\\Local\\Temp\\ipykernel_2064\\3611868607.py:104: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column][i] = self.replaceChar(df[column][i])\n",
            "C:\\Users\\leysh\\AppData\\Local\\Temp\\ipykernel_2064\\3611868607.py:105: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column][i] = self.removeStopWords(df[column][i])\n",
            "C:\\Users\\leysh\\AppData\\Local\\Temp\\ipykernel_2064\\3611868607.py:106: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column][i] = self.StemmWords(df[column][i])\n",
            "C:\\Users\\leysh\\AppData\\Local\\Temp\\ipykernel_2064\\3611868607.py:107: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column][i] = self.trimSpaces(df[column][i])\n"
          ]
        }
      ],
      "source": [
        "t = DataCleaner()\n",
        "df_train = t.clean(df_train, 'passage')\n",
        "df_test = t.clean(df_test, 'passage')\n",
        "df_validation = t.clean(df_validation, 'passage')\n",
        "df_train = t.clean(df_train, 'question')\n",
        "df_test = t.clean(df_test, 'question')\n",
        "df_validation = t.clean(df_validation, 'question')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===================================\n",
            "===        Removed Chars        ===\n",
            "===================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>count_removed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [symbol, count_removed]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===================================\n",
            "===        Removed Words        ===\n",
            "===================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>count_removed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [word, count_removed]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===================================\n",
            "===        Replaced Chars       ===\n",
            "===================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol_from</th>\n",
              "      <th>symbol_to</th>\n",
              "      <th>count_replaced</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>«</td>\n",
              "      <td>«</td>\n",
              "      <td>2246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>»</td>\n",
              "      <td>»</td>\n",
              "      <td>2233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>—</td>\n",
              "      <td>—</td>\n",
              "      <td>4524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>19367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>4010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>27875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>)</td>\n",
              "      <td>)</td>\n",
              "      <td>1430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>:</td>\n",
              "      <td>:</td>\n",
              "      <td>1395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>%</td>\n",
              "      <td>%</td>\n",
              "      <td>348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/</td>\n",
              "      <td>/</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>|</td>\n",
              "      <td>|</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>]</td>\n",
              "      <td>]</td>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[</td>\n",
              "      <td>[</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>!</td>\n",
              "      <td>!</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>*</td>\n",
              "      <td>*</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>&lt;</td>\n",
              "      <td>&lt;</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>&gt;</td>\n",
              "      <td>&gt;</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>3439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>&amp;</td>\n",
              "      <td>&amp;</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>=</td>\n",
              "      <td>=</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>$</td>\n",
              "      <td>$</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>#</td>\n",
              "      <td>#</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>(</td>\n",
              "      <td>(</td>\n",
              "      <td>1337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>{</td>\n",
              "      <td>{</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>}</td>\n",
              "      <td>}</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   symbol_from symbol_to count_replaced\n",
              "0            «         «           2246\n",
              "1            »         »           2233\n",
              "2            —         —           4524\n",
              "3            .         .          19367\n",
              "4            -         -           4010\n",
              "5            ,         ,          27875\n",
              "6            )         )           1430\n",
              "7            :         :           1395\n",
              "8            %         %            348\n",
              "9            /         /            198\n",
              "10           |         |              7\n",
              "11           ]         ]            154\n",
              "12           [         [            149\n",
              "13           !         !             54\n",
              "14           *         *             13\n",
              "15           <         <              6\n",
              "16           >         >             19\n",
              "17           ?         ?           3439\n",
              "18           &         &              5\n",
              "19           =         =              9\n",
              "20           $         $             10\n",
              "21           #         #              6\n",
              "22           (         (           1337\n",
              "23           {         {              3\n",
              "24           }         }              1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===================================\n",
            "===        Stemmed Words        ===\n",
            "===================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_from</th>\n",
              "      <th>word_to</th>\n",
              "      <th>count_replaced</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>выставочныи</td>\n",
              "      <td>выставочны</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>станция</td>\n",
              "      <td>станц</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>московского</td>\n",
              "      <td>московск</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>монорельса</td>\n",
              "      <td>монорельс</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>расположена</td>\n",
              "      <td>располож</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50960</th>\n",
              "      <td>себестоимость</td>\n",
              "      <td>себестоим</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50961</th>\n",
              "      <td>ювелирная</td>\n",
              "      <td>ювелирн</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50962</th>\n",
              "      <td>завоеван</td>\n",
              "      <td>завоева</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50963</th>\n",
              "      <td>новорожденные</td>\n",
              "      <td>новорожден</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50964</th>\n",
              "      <td>бодрит</td>\n",
              "      <td>бодр</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50965 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           word_from     word_to count_replaced\n",
              "0        выставочныи  выставочны              7\n",
              "1            станция       станц              7\n",
              "2        московского    московск             26\n",
              "3         монорельса   монорельс              2\n",
              "4        расположена    располож             21\n",
              "...              ...         ...            ...\n",
              "50960  себестоимость   себестоим              1\n",
              "50961      ювелирная     ювелирн              1\n",
              "50962       завоеван     завоева              1\n",
              "50963  новорожденные  новорожден              1\n",
              "50964         бодрит        бодр              1\n",
              "\n",
              "[50965 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dfs = t.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'выставк достижен народн хозяиств 1959 1991 год выставк достижен народн хозяиств ссср 1992 2014 год всероссииск выставочны центр выставочны комплекс останкинск раион север восточн административн округ город москв второ величин выставочны комплекс город вход 50 крупнеиш выставочн центр мир ежегодн вднх посеща 30 млн гост 1 август 2019 год выставк отпразднова 80 летн юбил территориальн вднх объедин парк останкин главн ботаническ сад общ площад составля 700 га 240 2 га площад вднх 75 6 га площад парк останкин 361 га площад гбс 9 5 га музеин выставочны центр рабоч колхозниц площад арко главн вход территор выставк располож множеств шедевр архитектур 49 объект вднх призна памятник культурн наслед'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.passage[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.to_json(fileNameData(trainPartName), force_ascii=False, lines=True, orient='records')\n",
        "df_test.to_json(fileNameData(testPartNameRaw), force_ascii=False, lines=True, orient='records')\n",
        "df_validation.to_json(fileNameData(validatePartName), force_ascii=False, lines=True, orient='records')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Number Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>passage</th>\n",
              "      <th>label</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>вода марсе ?</td>\n",
              "      <td>гидросфера марса — это совокупность водных зап...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>состоит англия евросоюзе ?</td>\n",
              "      <td>полночь 31 января 1 февраля 2020 года централь...</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>деиствительно ссср адвокатов ?</td>\n",
              "      <td>семен львович ария — советскии россиискии юрис...</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>чума оране ?</td>\n",
              "      <td>чума — это абсурд , осмысливается форма сущест...</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>кетчуп читосе ?</td>\n",
              "      <td>текущии каталог продукции размещен саите произ...</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         question  \\\n",
              "0                    вода марсе ?   \n",
              "1      состоит англия евросоюзе ?   \n",
              "2  деиствительно ссср адвокатов ?   \n",
              "3                    чума оране ?   \n",
              "4                 кетчуп читосе ?   \n",
              "\n",
              "                                             passage  label  idx  \n",
              "0  гидросфера марса — это совокупность водных зап...   True    0  \n",
              "1  полночь 31 января 1 февраля 2020 года централь...  False    1  \n",
              "2  семен львович ария — советскии россиискии юрис...  False    2  \n",
              "3  чума — это абсурд , осмысливается форма сущест...   True    3  \n",
              "4  текущии каталог продукции размещен саите произ...   True    4  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = loadJSONL(fileNameData(testPartName), lines=True)\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ True False False  True  True  True  True  True  True False]\n"
          ]
        }
      ],
      "source": [
        "y_test = df_test['label'].to_numpy()\n",
        "print(y_test[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "rng_score = []\n",
        "for _ in range(5):\n",
        "    validation_pred = [(True if b == 1 else False) for b in np.random.randint(2, size=( len(y_test)))]\n",
        "    rng_score.append(accuracy_score(y_test, validation_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.5066991473812423,\n",
              " 0.48964677222898906,\n",
              " 0.4725943970767357,\n",
              " 0.5140073081607796,\n",
              " 0.47990255785627284]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rng_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TF-IDF + LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import codecs\n",
        "import json\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pickle\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_feature_DaNetQA(row):\n",
        "    res = str(row[\"question\"]).strip()\n",
        "    label = row.get(\"label\")\n",
        "    return res, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_features_DaNetQA(path, vect):\n",
        "    with codecs.open(path, encoding='utf-8-sig') as reader:\n",
        "        lines = reader.read().split(\"\\n\")\n",
        "        lines = list(map(json.loads, filter(None, lines)))\n",
        "    res = list(map(build_feature_DaNetQA, lines))\n",
        "    texts = list(map(lambda x: x[0], res))\n",
        "    labels = list(map(lambda x: x[1], res))\n",
        "    ids = [x[\"idx\"] for x in lines]\n",
        "    return (vect.transform(texts), labels), ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit_DaNetQA(train, labels):\n",
        "    clf = LogisticRegression()\n",
        "    return clf.fit(train, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_DaNetQA(train_path, val_path, test_path, vect):\n",
        "    train, _ = build_features_DaNetQA(train_path, vect)\n",
        "    val, _ = build_features_DaNetQA(val_path, vect)\n",
        "    test, ids = build_features_DaNetQA(test_path, vect)\n",
        "    clf = fit_DaNetQA(*train)\n",
        "    try:\n",
        "        test_score = clf.score(*test)\n",
        "    except ValueError:\n",
        "        test_score = None\n",
        "    test_pred = clf.predict(test[0])\n",
        "    return clf, {\n",
        "        \"train\": clf.score(*train),\n",
        "        \"val\": clf.score(*val),\n",
        "        \"test\": test_score,\n",
        "        \"test_pred\": [{\"idx\": idx, \"label\": str(label).lower()} for idx, label in zip(ids, test_pred)]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Pre-Trained TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'rm' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget https://russiansuperglue.com/tasks/tf_idf\n",
        "!unzip tf_idf_baseline.zip\n",
        "!rm tf_idf_baseline.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leysh\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.21.3 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "c:\\Users\\leysh\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.21.3 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "vect = joblib.load(\"tfidf.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Score Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### On Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_path = fileNameData(trainPartNameRaw)\n",
        "test_path = fileNameData(testPartNameRaw)\n",
        "val_path = fileNameData(validatePartNameRaw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on train data = 0.8010291595197255\n",
            "Accuracy on validation data = 0.37393422655298414\n"
          ]
        }
      ],
      "source": [
        "_, DaNetQA_scores = eval_DaNetQA(train_path, test_path, val_path, vect)\n",
        "print(f'Accuracy on train data = {DaNetQA_scores[\"train\"]}')\n",
        "print(f'Accuracy on validation data = {DaNetQA_scores[\"val\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### On Pre-Cleaned Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_path = fileNameData(trainPartName)\n",
        "test_path = fileNameData(testPartName)\n",
        "val_path = fileNameData(validatePartName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on train data = 0.8061749571183533\n",
            "Accuracy on validation data = 0.5481120584652862\n"
          ]
        }
      ],
      "source": [
        "_, DaNetQA_Cleared_scores = eval_DaNetQA(train_path, test_path, val_path, vect)\n",
        "print(f'Accuracy on train data = {DaNetQA_Cleared_scores[\"train\"]}')\n",
        "print(f'Accuracy on validation data = {DaNetQA_Cleared_scores[\"val\"]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Impot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 0:\n",
        "    !pip install tensorflow\n",
        "    !pip install pandas\n",
        "    !pip install scipy\n",
        "    !pip install transformers\n",
        "    !pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuda is available: True\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "import torch\n",
        "print(f\"Cuda is available: {torch.cuda.is_available()}\")\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.nn.utils import clip_grad_norm_ as clip_grad_norm \n",
        "\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers.optimization import AdamW\n",
        "\n",
        "from scipy.special import expit\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import seed_everything\n",
        "from utils import seed_worker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Encode text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collectAttentionMask(seq):\n",
        "    return [float(i > 0) for i in seq]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collectTokenType(row, sepTokenIdx):\n",
        "    row = np.array(row)\n",
        "    mask = row == sepTokenIdx\n",
        "\n",
        "    whereMask = np.where(mask)[0]\n",
        "    idx = whereMask[0]\n",
        "    idx1 = whereMask[1]\n",
        "\n",
        "    token_type_row = np.zeros(row.shape[0], dtype=np.int32)\n",
        "    token_type_row[idx + 1:idx1 + 1] = 1\n",
        "    return token_type_row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode_text_pairs(tokenizer, sentences):\n",
        "    ENCODE_BATCH_SIZE = 20000\n",
        "    input_ids, attention_masks, token_type_ids = [], [], []\n",
        "    \n",
        "    clsTokenText = '[CLS]'\n",
        "    sepTokenText = '[SEP]'\n",
        "    sepTokenIdx = tokenizer.convert_tokens_to_ids(sepTokenText)\n",
        "\n",
        "    TEXT1_MAX = int(MAX_LEN*.75) # выделяет 75% размера слов для контекста\n",
        "    TEXT2_MAX = MAX_LEN - TEXT1_MAX # остальные слова это вопрос\n",
        "    for _, i in enumerate(range(0, len(sentences), ENCODE_BATCH_SIZE)):\n",
        "        # обрезаем предложение слов больше чем MAX_LEN\n",
        "        tokenized_texts = []\n",
        "        for sentence_context, sentence_question  in sentences[i:i + ENCODE_BATCH_SIZE]:\n",
        "            p1 = [clsTokenText] + tokenizer.tokenize(sentence_context)\n",
        "            p2 = [sepTokenText] + tokenizer.tokenize(sentence_question) + [sepTokenText]\n",
        "            final_tokens = p1[:TEXT1_MAX] + p2[:TEXT2_MAX]\n",
        "            tokenized_texts.append(final_tokens)\n",
        "\n",
        "        # токенизируем\n",
        "        b_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "        b_input_ids = pad_sequences(\n",
        "            b_input_ids, \n",
        "            maxlen=MAX_LEN, \n",
        "            dtype='long', \n",
        "            truncating='post', \n",
        "            padding='post')\n",
        "        input_ids.append(b_input_ids)\n",
        "\n",
        "        # маска внимания\n",
        "        b_attention_masks = [collectAttentionMask(seq) for seq in b_input_ids]\n",
        "        attention_masks.append(b_attention_masks)\n",
        "\n",
        "        # тип токена\n",
        "        b_token_type_ids = [collectTokenType(row, sepTokenIdx) for row in b_input_ids]\n",
        "        token_type_ids.append(b_token_type_ids)\n",
        "        \n",
        "    return np.vstack(input_ids), np.vstack(attention_masks), np.vstack(token_type_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "def createDataLoader(set_ids, all_ids, input_ids, attention_masks, token_type_ids, all_labels, BATCH_SIZE_LOADER):\n",
        "    mask = np.array([sid in set_ids for sid in all_ids])\n",
        "\n",
        "    inputs = input_ids[mask]\n",
        "    masks = attention_masks[mask]\n",
        "    type_ids_dev = token_type_ids[mask]\n",
        "    labels = all_labels[mask]\n",
        "\n",
        "    t_inputs = torch.tensor(inputs)\n",
        "    t_masks = torch.tensor(masks)\n",
        "    t_type_ids_dev = torch.tensor(type_ids_dev)\n",
        "    t_labels = torch.tensor(labels)\n",
        "\n",
        "    t_dataset = TensorDataset(\n",
        "        t_inputs, \n",
        "        t_masks, \n",
        "        t_type_ids_dev, \n",
        "        t_labels)\n",
        "    t_sampler = SequentialSampler(t_dataset)\n",
        "\n",
        "    return DataLoader(\n",
        "        dataset=t_dataset, \n",
        "        sampler=t_sampler, \n",
        "        batch_size=BATCH_SIZE_LOADER, \n",
        "        worker_init_fn=seed_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getYFromDataLoader(dl):\n",
        "    return np.argmax(dl.dataset.__dict__['tensors'][3], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluateModel(model, in_dataloader, device):\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    accumulate_loss = 0\n",
        "    accumulate_step = 0\n",
        "    for _, batch in enumerate(in_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_token_type_ids, b_labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids = b_token_type_ids, \n",
        "                attention_mask = b_input_mask, \n",
        "                labels = b_labels)\n",
        "            loss, logits = outputs[:2]\n",
        "            \n",
        "            accumulate_loss += loss.item()\n",
        "            accumulate_step += 1\n",
        "\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            predictions.append(logits)\n",
        "\n",
        "    avg_loss = accumulate_loss / accumulate_step\n",
        "\n",
        "    predictions = expit(np.vstack(predictions))\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    y_true = getYFromDataLoader(in_dataloader)\n",
        "    score = accuracy_score(y_true, predictions)\n",
        "\n",
        "    return score, avg_loss, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train One Iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trainModelIteration(model, optimizer, scheduler, in_dataloader, MAX_GRAD_NORM, EPOCH_INDEX):\n",
        "    model.train() \n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    predictions = []\n",
        "    accumulate_loss = 0\n",
        "    accumulate_step = 0\n",
        "\n",
        "    nStep = len(in_dataloader)\n",
        "    for step, batch in enumerate(in_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_token_type_ids, b_labels = batch\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(\n",
        "            b_input_ids,\n",
        "            token_type_ids = b_token_type_ids, \n",
        "            attention_mask = b_input_mask, \n",
        "            labels = b_labels\n",
        "            )\n",
        "        loss, logits = outputs[:2]\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "\n",
        "        loss.backward()\n",
        "        clip_grad_norm(model.parameters(), MAX_GRAD_NORM)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        epochLoss = loss.item()\n",
        "        accumulate_loss += epochLoss\n",
        "        accumulate_step += 1\n",
        "        \n",
        "        print(f\"Epoch {EPOCH_INDEX} Step {step} of {nStep}, loss = {epochLoss}\")\n",
        "\n",
        "    avg_loss = accumulate_loss / accumulate_step\n",
        "\n",
        "    predictions = expit(np.vstack(predictions))\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    y_true = getYFromDataLoader(in_dataloader)\n",
        "    score = accuracy_score(y_true, predictions)\n",
        "\n",
        "    return score, avg_loss, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "text1_id, text2_id, label_id, index_id = 'passage', 'question', 'label', 'idx'\n",
        "l2i = {False: 0, True:1}\n",
        "part2indices = {p:set() for p in parts}\n",
        "\n",
        "all_ids, all_sentences, all_labels = [], [], []\n",
        "idxMax = 0\n",
        "for p in parts:\n",
        "    df = pd.read_json(fileNameData(p), lines=True)\n",
        "    ids = idxMax + df[index_id].to_numpy()\n",
        "    all_ids.extend(ids)\n",
        "    idxMax = np.max(all_ids)\n",
        "    \n",
        "    part2indices[p] = ids\n",
        "    all_labels.extend(df[label_id].to_numpy())\n",
        "    all_sentences.extend(\n",
        "        np.array(\n",
        "            np.column_stack([df[text1_id].to_numpy(), \n",
        "            df[text2_id].to_numpy()])\n",
        "        ).tolist())\n",
        "\n",
        "all_ids = np.array(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(total) 2570\n",
            "len(l2i) 2\n"
          ]
        }
      ],
      "source": [
        "print ('len(total)', len(all_sentences))\n",
        "i2l = {l2i[l]:l for l in l2i}\n",
        "print ( 'len(l2i)', len(l2i) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_indices = np.array([l2i[l] for l in all_labels])\n",
        "labels = np.zeros((len(all_ids), len(l2i)))\n",
        "for _, i in enumerate(label_indices):\n",
        "    labels[_, i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test =  label_indices[np.array([sid in part2indices['val_v1'] for sid in all_ids])]\n",
        "y_train =  label_indices[np.array([sid in part2indices['train_v1'] for sid in all_ids])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model RuBert-Cased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __POOL_MODEL:\n",
        "    from utils import PoolBertForSequenceClassification as BertModel\n",
        "else:\n",
        "    from transformers import BertForSequenceClassification as BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 128\n",
        "MAX_LEN = 256\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "BATCH_SIZE_LOADER = 8\n",
        "EPOCHS_LIMIT = 25\n",
        "LEARNING_RATE = 3e-5\n",
        "MAX_GRAD_NORM = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget \"http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_pt.tar.gz\"\n",
        "!tar -xvzf rubert_cased_L-12_H-768_A-12_pt.tar.gz\n",
        "!rm rubert_cased_L-12_H-768_A-12_pt.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d:\\New folder\\New folder\\DSnML_Innopolis2022\\00_Final_Attestation\\rubert_cased_L-12_H-768_A-12_pt/\n"
          ]
        }
      ],
      "source": [
        "model_path = os.path.join(base_path, 'rubert_cased_L-12_H-768_A-12_pt/')\n",
        "print(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### One-Hot Encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    pretrained_model_name_or_path = os.path.join(base_path, model_path),\n",
        "    do_lower_case=True,\n",
        "    max_length=MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_ids, attention_masks, token_type_ids = encode_text_pairs(tokenizer, all_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prepeare Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataloader = createDataLoader(part2indices['val_v1'], \n",
        "    all_ids, input_ids, attention_masks, token_type_ids, labels, BATCH_SIZE_LOADER)\n",
        "train_dataloader = createDataLoader(part2indices['train_v1'], \n",
        "    all_ids, input_ids, attention_masks, token_type_ids, labels, BATCH_SIZE_LOADER)\n",
        "validate_dataloader = createDataLoader(part2indices['val_v1'], \n",
        "    all_ids, input_ids, attention_masks, token_type_ids, labels, BATCH_SIZE_LOADER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape: torch.Size([1750, 256])\n",
            "Validation set shape: torch.Size([822, 256])\n",
            "Validation set shape: torch.Size([822, 256])\n"
          ]
        }
      ],
      "source": [
        "print (f'Training set shape: {train_dataloader.dataset.__dict__[\"tensors\"][0].shape}')\n",
        "print (f'Validation set shape: {test_dataloader.dataset.__dict__[\"tensors\"][0].shape}')\n",
        "print (f'Validation set shape: {validate_dataloader.dataset.__dict__[\"tensors\"][0].shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Pre-Trained BERT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed_everything(SEED)\n",
        "config_path = os.path.join(base_path, model_path, 'bert_config.json')\n",
        "conf = BertConfig.from_json_file(config_path)\n",
        "conf.num_labels = len(l2i)\n",
        "\n",
        "output_model_file = os.path.join(base_path, model_path, 'pytorch_model.bin')\n",
        "\n",
        "model = BertModel(conf)\n",
        "\n",
        "model.load_state_dict(torch.load(output_model_file), strict=False)\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "##### Limit learning for BERT layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Optimizer & Scheduler\n",
        "Задаем гиперпараметры для цикла обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "219\n"
          ]
        }
      ],
      "source": [
        "nStep = len(train_dataloader)\n",
        "print(nStep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leysh\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters, \n",
        "    lr=LEARNING_RATE, \n",
        "    correct_bias=False)\n",
        "    \n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, \n",
        "    max_lr=LEARNING_RATE, \n",
        "    steps_per_epoch=nStep, \n",
        "    epochs=EPOCHS_LIMIT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_train_predict = []\n",
        "all_test_predict = []\n",
        "\n",
        "all_avg_train_loss = []\n",
        "all_avg_test_loss = []\n",
        "\n",
        "all_train_acc = []\n",
        "all_test_acc = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for iEpoch in range(3):\n",
        "\n",
        "    train_score, avg_train_loss, y_train_prediction = trainModelIteration(model, optimizer, scheduler, train_dataloader, MAX_GRAD_NORM, iEpoch)\n",
        "    all_train_acc.append(train_score)\n",
        "    all_avg_train_loss.append(avg_train_loss)\n",
        "    all_train_predict.append(y_train_prediction)\n",
        "\n",
        "    ### evaluate test\n",
        "    test_score, avg_test_loss, y_test_prediction = evaluateModel(model, test_dataloader, device)\n",
        "    all_test_acc.append(test_score)\n",
        "    all_avg_test_loss.append(avg_test_loss)\n",
        "    all_test_predict.append(y_test_prediction)\n",
        "\n",
        "    # score test\n",
        "    print(f'Epoch {iEpoch} average train_loss: {avg_train_loss:.6f} test_loss: {avg_test_loss:.6f} test_score {test_score:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x20076116760>]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(all_train_acc)\n",
        "plt.plot(all_test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x2007618c5b0>]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8l0lEQVR4nO3deXxU9b3/8fdkm4SQhQSyQYAgyKrIqii4gVhQ1JYutlfUq/WWigukWqXaX6ttpXax1CpSrMv1Ult7L6i4tBWVRRRlDagsogQSQkIICZkkkGVmzu+PbxbGhCUxyTfJvJ6PxzyS8z3nZD4zQObN93y/3+NyHMcRAACAJSG2CwAAAMGNMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAqjDbBZwJv9+vgwcPKiYmRi6Xy3Y5AADgDDiOo7KyMqWlpSkk5OT9H50ijBw8eFDp6em2ywAAAC2Qm5urPn36nHR/pwgjMTExksyLiY2NtVwNAAA4Ex6PR+np6fWf4yfTKcJI3aWZ2NhYwggAAJ3M6YZYMIAVAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgVae4UR4AAPgKvFXS8RLp+NHar7WPyhO2x9wspZxjpTzCCAAAnYHjSFWeUweK+sBxNHB/zbHT//y+EwgjAAAEpaLPpbxNXwoTTYWNo5Lja/nzuEKkyHgpKl6K6tHwiKzd7jW4NV5NixBGAACw4WiOtGqBtP3vkuM/8/PCok4SKE5si28cNtyxUkjHHCpKGAEAoD2VH5be+7206RnJV23a+k6QYlKbDhMnBoqoeCk8ymLxbYMwAgBAe6j0SOufkNY/KVWXm7aMS6QpP5N6j7Fbm2WEEQAA2lJNpekFWfs76XixaUsbJU3+mXTWZXZr6yAIIwAAtAWfV9r2N2n1ryXPAdOWOEia/FNp6DWSy2W3vg6EMAIAQGtyHGnna9K7v5CKPjNtsb2lS+dLI78rhfLR+2W8IwAAtJa9a6S3fy4d3GK2oxKkST+Sxn1fCo+0WlpHRhgBAOCrytsivfOQtHe12Q6PlibMkS68Q4qMs1paZ0AYAQCgpQ5/Jq36pbTjVbMdEi6Nu1WadI/UvZfd2joRwggAAM1VesAMTM36a+2CZS5p5PVmXEiPfrar63QIIwAAnKljxWbBsg1PS74q0zb4KunyB6XkYXZr68QIIwAAnE5VufThIumDP5mb1UlSv4ukKT+X0sdbLa0rIIwAAHAy3ipp8/PS2t9KFYdNW8q5ZsGygZNZK6SVEEYAAPgyv0/a/g9p1SNSaY5pSxhgLscM+3qHveFcZ0UYAQCgjuNIu/8pvfOwdHinaeueIl16nzRqlhQabre+LoowAgCAJO1bJ739kHRgg9mOjJMmZkrj/0uK6Ga3ti6OMAIACG7520xPyOdvm+2wKOmCH0oX3SVF9bBbW5AgjAAAgtPhz6RVv5J2vGK2Q8KkMTdLF98rxaTYrCzoEEYAAMGlZJ+0+lFp+98bFiwbMVO6/AEzSBXtjjACAAgOnnwzRXfLC5K/xrQNuVq67CdS8nC7tQU5wggAoGurOCKte0za+BfJW2naBlwmXf5Tqc8Yu7VBEmEEANBVVZZKHzxhVk6tLjdt6RdIk38q9Z9otzYEIIwAALqW6grpoz9L7/9Rqjxq2lJHmp6QgVNYNbUDIowAALoGb5W06TlzI7uKQtPWc7AZmDr0GkJIB0YYAQB0bj6vlPVXac1vJM8B09ajv3TpfOmcb0khoVbLw+kRRgAAnZPfL32yTFr9iFS817TFpEmX3MvS7Z0MYQQA0Lk4jrT7TendX0qFO0xbt57SpExp7K1SeKTd+tBshBEAQOfgONIX75oQcnCLaXPHSRfdKZ3/Q8nd3W59aDHCCACg49u/Xnr3F9L+9812eLR0wWzpwju5f0wXQBgBAHRcB7NMT8jnK812qFsad6u5m273XlZLQ+shjAAAOp7CXeYmdjtXmO2QMGnUDeYmdnF97NaGVkcYAQB0HMV7a29i95IkR5JLOvfb0qX3cxO7LiykOQcvWLBA48aNU0xMjJKSknTddddp9+7dpzxn9erVcrlcjR67du36SoUDALqQ0jzptbnSE+PM3XTlSENnSLevl76xhCDSxTWrZ2TNmjWaM2eOxo0bJ6/XqwceeEBTp07Vjh07FB0dfcpzd+/erdjY2PrtXr241gcAQa+y1CxWtuFpyVdl2gZOkS5/UEobZbc2tJtmhZF//etfAdvPPfeckpKStHnzZl188cWnPDcpKUnx8fHNLhAA0EV98a706p0Nq6b2u8iEkH4X2q0L7e4rjRkpLS2VJCUkJJz22FGjRqmyslLDhg3Tgw8+qMsuu+ykx1ZVVamqqqp+2+PxfJUyAQAdSVWZ9NaD0ubnzXaP/tJVv5fOmsz9Y4JUs8aMnMhxHGVmZmrixIkaMWLESY9LTU3VkiVLtGzZMi1fvlyDBw/W5MmTtXbt2pOes2DBAsXFxdU/0tPTW1omAKAj2btaWnRhQxAZ/wPphx9wN90g53Icx2nJiXPmzNEbb7yhdevWqU+f5k2zmjFjhlwul1asWNHk/qZ6RtLT01VaWhow7gQA0ElUlUtv/0za+BezHd9XunaRlDHJbl1oUx6PR3Fxcaf9/G7RZZo777xTK1as0Nq1a5sdRCTpggsu0NKlS0+63+12y+12t6Q0AEBHk/2e9Ooc6eh+sz32VumKh1m+HfWaFUYcx9Gdd96pl19+WatXr1ZGRkaLnnTr1q1KTU1t0bkAgE6iukJ6+yFpw5/Ndly6dO0T0oBLrZaFjqdZYWTOnDl68cUX9eqrryomJkYFBQWSpLi4OEVFRUmS5s+fr7y8PL3wwguSpIULF6p///4aPny4qqurtXTpUi1btkzLli1r5ZcCAOgw9n8gvXK7VJJttsfcLF3xCymSS+1orFlh5KmnnpIkXXrppQHtzz33nG6++WZJUn5+vnJycur3VVdX65577lFeXp6ioqI0fPhwvfHGG5o+ffpXqxwA0PFUHzP3kvlwkSRHiu0tXfMnaeBk25WhA2vxANb2dKYDYAAAFuV8JL3yQ6n4C7M96gbpykekyDi7dcGaNh3ACgBAvZrj5qZ2HzwhyZFiUk1vyKArbFeGToIwAgBouQObTG9I0Wdme+T3pK89IkX1sFsXOhXCCACg+WoqpdULpA8elxy/1D1ZmvG4NPhrtitDJ0QYAQA0T95mM1PmcO3d18/9jvS1X0vdTn9rEKAphBEAwJnxVpk77K77g+T4pOhe0tULpaFX264MnRxhBABwegezzNiQwh1me8RMadpvpehEq2WhayCMAABOzlstvfc7ae3vTG9It57S1Y9Jw661XRm6EMIIAKBpBR9LL/9QOvSx2R52nXTV76XonlbLQtdDGAEABPLVmHEhax6V/F4pKsGEkBHfsF0ZuijCCACgwaEd0iuzpfxtZnvI1dLVf5C6J9mtC10aYQQAIPm80vsLpdW/lvw1UmR8bW/ITMnlsl0dujjCCAAEu8Jdpjfk4FazPXi66Q2JSbFbF4IGYQQAgk1lqVnG/cAm6cBGKXuN5Ks2N7Sb9lvp3G/TG4J2RRgBgK7M7zcrpR7YKB3YYALI4d2SvnTD9kFXSjP+KMWmWikTwY0wAgBdybHi2h6PDSaA5G2RqjyNj+vRX+ozXuozTkofL6WOpDcE1hBGAKCz8nmlwk9rez02SbkbpOIvGh8XHi31Ht0QPHqPlbr3av96gZMgjABAZ1FeWBs8Nkq5G6WDW6SaY42PSxxUGzzGma+9hkqh/LpHx8XfTgDoiLzVZuXTuh6PAxulo/sbH+eOlXqPMT0efcaZ77l7LjoZwggAdASegw2h48AmKT9L8lZ+6SCX1GtIQ49Hn3FSz8FSSIiNioFWQxgBAFuqyqV1j0nb/i558hrvj+rREDr6jDPjPiLj2r9OoI0RRgCgvTmO9PH/Siv/n1SWb9pcIVLy8NrgUXvJJfEsZrggKBBGAKA9Hdwq/fM+Kfcjs92jvzTlIWngFMnd3WppgC2EEQBoDxVF0jsPS1tekORI4d2ki++RLpgjhUfarg6wijACAG3JVyNtfEZa9YhUVWrazvmW6Q2J6223NqCDIIwAQFvZu1r65/3S4Z1mO+VcadpvpH4TrJYFdDSEEQBobSX7pbcekHa+ZrajEqTJ/08afaMUEmq3NqADIowAQGupPia9v1B6/49mjRBXqDTu+9Jl8800XQBNIowAwFflONKOV6R/Pyh5Dpi2/pPMJZnkYVZLAzoDwggAfBWHPjVTdfe9Z7bj0qUrfyUNvYY1QoAzRBgBgJY4VmxmyGx6RnL8UlikNHGedOFdUkQ329UBnQphBACaw++TNj8vvfsL6XiJaRt2rTT1l1J8X6ulAZ0VYQQAztT+D6Q3f2zupitJScOkaY9KGRfbrQvo5AgjAHA6pQfMfWQ+WWa2I+Okyx6Uxt4ihfJrFPiq+FcEACdTUymt/5P03mNSzTFJLmnMzdLlP5WiE21XB3QZhBEA+DLHkXa/Kf1rvnR0v2nrO8Fckkkdabc2oAsijADAiQ7vlv51v/TFu2Y7Jk2a+gtpxEym6gJthDACAJJUWSqtflTa8GfJ75VCI8w03YnzJHd329UBXRphBEBw8/ulrL9K7zwkVRw2bYOvkq78pZQwwG5tQJAgjAAIPo4jFe6QdrwqffqyVPSZaU8cJE37tTRwit36gCBDGAEQHBxHys+SdqwwIaT4i4Z9ETHSpfdL4/9LCouwViIQrAgjALouv1/K22TCx84V0tGchn2hbmngZLN66tlfk6LirZUJBDvCCICuxe+Tcj6sDSCvSWUHG/aFd5MGXWECyKCpkjvGXp0A6hFGAHR+Pq+0f11tAHldqihs2BcRIw3+mrmL7sAp3MQO6IAIIwA6J2+1lL3GBJBdb0jHixv2RcaZGTHDrpUGXCqFR1orE8DpEUYAdB41lWYxsh2vSrv/KVWVNuzrligNuVoado3U/2IGogKdCGEEQMdWXSHtWWkGoH72b6m6vGFf92Rp6AxzCabfRdy0Duik+JeL4Ja7QTqYJY2eJYVH2a4GdSo90p63pB2vSHvelrzHG/bF9jbhY9i1Uvp4KSTUWpkAWgdhBMHJcaT1T0orfyo5fmnz89I3n5WShtiuLHgdLzGXXnaskL54R/JVN+yL72fCx7BrpbTRUkiIvToBtDrCCIJP9THptbulj/9htsOipMJPpSWXSl9bYG4Rzw3R2kdpnukB2fmaGYzq9zbsSxxUG0CukVLO5c8E6MKa9d+LBQsWaNy4cYqJiVFSUpKuu+467d69+7TnrVmzRmPGjFFkZKQGDBigxYsXt7hg4Cs5miM9e6UJIq5QadpvpLnbpbMmm0sBr8+V/jFLOlZ82h+FFvDVSPvel97+ufTURdIfhpn3/It3TBBJGi5dOl+6/UPpjo3S5J9KqSMJIkAX16yekTVr1mjOnDkaN26cvF6vHnjgAU2dOlU7duxQdHR0k+dkZ2dr+vTpuu2227R06VK9//77uv3229WrVy/NnDmzVV4EcEay35P+9ybp2BEz8+Jb/y1lTDL7/uP/pA8XmQ/Jna9JeVulmU9L/S60WnKXUHZI+vxt0wPyxarAGTBySX3GmhVQh10r9RxkrUwA9rgcx3FaevLhw4eVlJSkNWvW6OKLL27ymPvuu08rVqzQzp0769tmz56tbdu2af369Wf0PB6PR3FxcSotLVVsbGxLy0Wwchzpoz9L//6J5PhMl//1f5Xi+zY+9uBW6f9ukYr3Sq4Q6eIfSxffyyyN5vD7pLzNJnzseUvK3xa4PyrBLD42aKp01uVSdKKdOgG0uTP9/P5Kv2FLS83/cBISEk56zPr16zV16tSAtiuvvFLPPPOMampqFB4e3uicqqoqVVVV1W97PJ6vUiaCWU2l9Po8aduLZvvc70gz/njymTNpo6QfrJXe/LE5Z82vzViGbzwtxae3X92dTUWR9Pk7tb0f75jBqCdKG2XCx6Cp5ntmwAA4QYvDiOM4yszM1MSJEzVixIiTHldQUKDk5OSAtuTkZHm9XhUVFSk1NbXROQsWLNBDDz3U0tIAo/SA9NINprfDFSpN/YV0we2nH3/gjpG+/pT5X/vr86Sc9dLii6Rr/mQuJcDcgC5/q1n/Y89bUt4WSSd0skbGmXE4g6aam9F1T7JWKoCOr8Vh5I477tD27du1bt260x7r+tIv/7orQ19urzN//nxlZmbWb3s8HqWn879SNMO+9834kIrDUlQP6VvPm2XBm+Pcb5nxDMtuNZcd/nGjmWlz5YLgvL/JsWKz+umelWYMyLGiwP0p59SGjyukPuO4tAXgjLXot8Wdd96pFStWaO3aterTp88pj01JSVFBQUFAW2FhocLCwpSY2PS1YrfbLbfb3ZLSEOwcR9r4F+lf95vZGcnnSNcvlXr0b9nPS8iQbvm3tOpX0rqFZj2S/evNmiQpJ+8R7BIcRyrYXjv2423pwAazJkudiBjprMvMXXAHTpFi0+zVCqBTa1YYcRxHd955p15++WWtXr1aGRkZpz1nwoQJeu211wLa3nrrLY0dO7bJ8SJAi3mrpDd+JG39H7M9/BvStU9IEU3P9DpjoeHSlJ+bnpXlP5CKdktPXy5N/aU0/rauNe20stTMePl8pQkg5YH/kVDSsIbBp+nnc/8XAK2iWbNpbr/9dr344ot69dVXNXjw4Pr2uLg4RUWZAYHz589XXl6eXnjhBUlmau+IESP0gx/8QLfddpvWr1+v2bNn629/+9sZT+1lNg1Oy3NQemmWlLfJzIKZ8nPpwrtaPyhUFEmv3C7t+bfZPnuadO2TnXdGiONIh3eZe77sWSnlfhi48Fh4tDTgktrejysYxAugWc7087tZYeRkYzyee+453XzzzZKkm2++Wfv27dPq1avr969Zs0bz5s3Tp59+qrS0NN13332aPXv2mT4tYQSnlvOhGc9RfkiKjDeXUAZObrvncxxpwxLprQfNkuUxqdI3lkgZTU9v75DKC6Xt/5C2/U069EngvsRBtTNfrjDrrIRxyRRAy7RJGLGFMIKT2vSc9Oa9kr/GXEK4/q9SwoD2ee6Cj82aJEWfSXJJkzLN6qGhHfTyo7fK3Ptl299ML4jjM+2hEeYS1KCp5hJMwukvvwLAmSCMoGvzVkv//LG0+TmzPexa6dpFkrt7+9ZRXWEGy24xlyXVZ5w08y8tHzDb2hzHTLvd9qL08f9JlUcb9vUeK533XTO2ptvJ1woCgJYijKDrKiswl2VyP5LkMvcvmZhpdyDppy9LK+42S527Y6Wr/yCd80179XgOSttfkrL+Zgbc1olJk0Z+Rxr5PanX2fbqAxAU2mUFVqDd5W40N7Iry5fccdI3nzFjG2wb/nWp9xhp2fdNSFp2q5mVMu3R9uutqTku7XpDynpR2ruqYRpuWKQ0dIZ03vekjEtY/RRAh0PPCDqPLf8jvZFpBo32HCx9929S4lm2qwrk80prfyOt/a0JA4kDpZnPSGnntc3zOY4JP1kvmt6ZqhNundB3gjTyu9Lw68yKqADQzrhMg67DVyP9a7608WmzPeRq6euLzbLtHdW+ddLy/5I8eVJIuHTFQ9L5P5RCQlrn5x/Nlbb93QxGLf6ioT2urzTyevPoaEENQNAhjKBrKC+U/nGTlPOB2b7sAWnSPa33od6WjhVLK+6Udr1utgdeIV33lNS9V8t+XnWFtGOFGYya/Z7q7wUTHm0G8J73XanfxM7x3gAICoQRdH55m81CZp48s/T4zKelwdNsV9U8jiNtelb6908kb6UUnWR6dc50HRS/3wSxrBelHa9K1eUN+/pPMuNAhl7T/rOIAOAMMIAVnVvWi9JrcyVflVmE6/oXO+fsD5dLGnerGb/xf7dIh3dKS79hVoe9/KcnX069eG/DZZijOQ3tPTJMADn3O1KPfu3zGgCgjdEzgo7FV2NWNv1osdk++2tmddOuMACz5rj07wekTc+Y7bRRZnBr3diOSo/p/ch6seGylGR6hUZ83UzH7XtB17oXDoAujcs06HwqiqT/vVna957ZvuQ+6ZL7u94YiJ2vS6/OMQuQRXSXLvmxVPCJtPM1yXu89iCXuSPuyO9JQ66SIrrZrBgAWoTLNOhcDmZJL90gleaaD+ivLzZrY3RFQ682U32X/5e0/31p5f9r2Jc4qOEyTFxvayUCQHsijMC+7f8ws068lea+Mtf/TUoaYruqthXXR7rpNWndY9LWv5pekPP+wyycxmUYAEGGyzSw52iOtO4PZraJZKa+zvyLFBVvtSwAQOvgMg06JseRctZLHz5l1t+oW7J80o/MGiIsVQ4AQYcwgvbhrZI+WS59uEgq2N7QnnGJNHGudNbl1koDANhFGEHbKjtkLsNselaqKDRtYZFmgOb5s6XkYXbrAwBYRxhB2zi4VfpwsfTpcnNjO8ncvn7896XRN0vRiVbLAwB0HIQRtB6f14wD+WixGRdSp8946YLZZtny0HB79QEAOiTCCL66Y8XSlhekjX8x64RIUkiYNPzr5k61fcbYrQ8A0KERRtByh3ebXpBtf5dqjpm2bonS2FuksbdKsal26wMAdAqEETSP3y99/rb00VPSF+82tCePMANSz/mWFB5prz4AQKdDGMGZqSo3d5D9aLF05PPaRpe5b8r5s6X+E1k5FADQIoQRnFrJPmnD09KW/5GqSk2bO1YafaM0/japR3+b1QEAugDCCBpzHHMDtw+fkna/2bBKasJZphfkvO9K7hi7NQIAugzCCBrUVEqf/J9ZH+TQxw3tZ11uZsUMnCKFhNirDwDQJRFGIHnypU3PSJuek44VmbawKGnk9aYnpKvfQRcAYBVhJBh5q6SCT6S8TeZyzK43JL/X7IvtY8aCjL5R6pZgt04AQFAgjHR1jiMV75XyNksHNpkAUvBxwxLtddIvMKukDpkhhfLXAgDQfvjU6WoqjpjgkbfZBI+8zdLxksbHRSVIfcZKvcdIZ18ppY1q/1oBABBhpHOrqTS9HHWh48AmqSS78XGhbin1XKn32NoAMlrqkcG6IACADoEw0ln4/bWXWzadcLnlE8lf0/jYxIEnBI8xZnXUsIj2rxkAgDNAGOmoKooCx3nkbZYqSxsf1y0xMHj0Hi1F9Wj/egEAaCHCSEdQc1zK3x54ueXo/sbHhUVKqSNN+Og92gSQ+H5cbgEAdGqEEZvyt0lv3CMd3NIwtfZEPc+u7fUYY74mD5dCw9u/TgAA2hBhxJb8bdJ/XyNVHjXb0b0Cg0fv0VJknNUSAQBoD4QRG/K3Sy9ca4JIn/HSzKe53AIACFqEkfZW8IkJIsdLTA/IDcukyFjbVQEAYA13PWtPhz6VXrhGOl5sZr7MWk4QAQAEPcJIezm0Q/rvGdKxI2a10xuWMyYEAAARRtpH4a6GIJI6Upr1shQVb7sqAAA6BMJIWzu8uzaIFEkp50qzXmFRMgAATkAYaUuHP5Oev1qqKJRSzpFufFXqlmC7KgAAOhTCSFsp2iP9d20QSR4h3biCIAIAQBMII23hyBemR6T8kJQ0nCACAMApEEZaW30QKZCShkk3rZCiE21XBQBAh0UYaU3Fe81g1bKDUq8hpkckuqftqgAA6NAII62lOFt6fobkyZN6DpZuek3q3st2VQAAdHiEkdZQst/0iHgOmDvt3vSa1D3JdlUAAHQKhJGv6miOGSNSmislDjRBJCbZdlUAAHQazQ4ja9eu1YwZM5SWliaXy6VXXnnllMevXr1aLper0WPXrl0trbnjOJorPX+VVJojJZwl3fS6FJNiuyoAADqVZt+1t6KiQiNHjtR//ud/aubMmWd83u7duxUb23BTuF69Ovl4itIDZh2RozlSwgDp5tel2FTbVQEA0Ok0O4xMmzZN06ZNa/YTJSUlKT4+vtnndUileebSTMk+qUd/0yMSm2a7KgAAOqV2GzMyatQopaamavLkyVq1atUpj62qqpLH4wl4dBieg6ZHpCRbiu9ngkhcb9tVAQDQabV5GElNTdWSJUu0bNkyLV++XIMHD9bkyZO1du3ak56zYMECxcXF1T/S09Pbuswz48k3s2aK90rxfc2lmfgOUhsAAJ2Uy3Ecp8Unu1x6+eWXdd111zXrvBkzZsjlcmnFihVN7q+qqlJVVVX9tsfjUXp6ukpLSwPGnbSrsgJzaebIHikuXbr5DalHPzu1AADQCXg8HsXFxZ3289vK1N4LLrhAe/bsOel+t9ut2NjYgIdVZYdMj8iRPVJsH9MjQhABAKBVWAkjW7duVWpqJ5l5Ul4ovXCNVPSZFNu7Noj0t10VAABdRrNn05SXl+vzzz+v387OzlZWVpYSEhLUt29fzZ8/X3l5eXrhhRckSQsXLlT//v01fPhwVVdXa+nSpVq2bJmWLVvWeq+irZQflv77GunwLikmzQSRhAzbVQEA0KU0O4xs2rRJl112Wf12ZmamJOmmm27S888/r/z8fOXk5NTvr66u1j333KO8vDxFRUVp+PDheuONNzR9+vRWKL8NVRSZHpHDO6WY1NogMsB2VQAAdDlfaQBreznTATCtpuKICSKHPpG6p5jBqj0Htv3zAgDQhXToAawd2rFi6YVra4NIsukRIYgAANBmCCMnOlZc2yPysRSdZG5613OQ7aoAAOjSCCN1jpeYHpGCj6XoXiaI9BpsuyoAALo8wogkHT8qvXCdVLBd6tbTBJGkIbarAgAgKBBGjh+V/ufrUn6W1C1RummFlDTUdlUAAASN4A4jlaXS0m9IB7dIUQnSjSuk5OG2qwIAIKgEbxjx+6W/flvK2yxF9TA9IikjbFcFAEDQCd4wEhIijfu+GSNy46tSyjm2KwIAICg1ewXWLuXcb0lnXylFWr4RHwAAQSx4e0bqEEQAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwKpmh5G1a9dqxowZSktLk8vl0iuvvHLac9asWaMxY8YoMjJSAwYM0OLFi1tSKwAA6IKaHUYqKio0cuRIPfHEE2d0fHZ2tqZPn65JkyZp69at+slPfqK77rpLy5Yta3axAACg6wlr7gnTpk3TtGnTzvj4xYsXq2/fvlq4cKEkaejQodq0aZN+97vfaebMmc19egAA0MW0+ZiR9evXa+rUqQFtV155pTZt2qSampomz6mqqpLH4wl4AACArqnNw0hBQYGSk5MD2pKTk+X1elVUVNTkOQsWLFBcXFz9Iz09va3LBAAAlrTLbBqXyxWw7ThOk+115s+fr9LS0vpHbm5um9cIAADsaPaYkeZKSUlRQUFBQFthYaHCwsKUmJjY5Dlut1tut7utSwMAAB1Am/eMTJgwQStXrgxoe+uttzR27FiFh4e39dMDAIAOrtlhpLy8XFlZWcrKypJkpu5mZWUpJydHkrnEcuONN9YfP3v2bO3fv1+ZmZnauXOnnn32WT3zzDO65557WucVAACATq3Zl2k2bdqkyy67rH47MzNTknTTTTfp+eefV35+fn0wkaSMjAy9+eabmjdvnp588kmlpaXp8ccfZ1ovAACQJLmcutGkHZjH41FcXJxKS0sVGxtruxwAAHAGzvTzm3vTAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAq1oURhYtWqSMjAxFRkZqzJgxeu+990567OrVq+VyuRo9du3a1eKiAQBA19HsMPLSSy9p7ty5euCBB7R161ZNmjRJ06ZNU05OzinP2717t/Lz8+sfgwYNanHRAACg62h2GHnsscd066236vvf/76GDh2qhQsXKj09XU899dQpz0tKSlJKSkr9IzQ0tMVFAwCArqNZYaS6ulqbN2/W1KlTA9qnTp2qDz744JTnjho1SqmpqZo8ebJWrVp1ymOrqqrk8XgCHgAAoGtqVhgpKiqSz+dTcnJyQHtycrIKCgqaPCc1NVVLlizRsmXLtHz5cg0ePFiTJ0/W2rVrT/o8CxYsUFxcXP0jPT29OWUCAIBOJKwlJ7lcroBtx3EatdUZPHiwBg8eXL89YcIE5ebm6ne/+50uvvjiJs+ZP3++MjMz67c9Hg+BBACALqpZPSM9e/ZUaGhoo16QwsLCRr0lp3LBBRdoz549J93vdrsVGxsb8AAAAF1Ts8JIRESExowZo5UrVwa0r1y5UhdeeOEZ/5ytW7cqNTW1OU8NAAC6qGZfpsnMzNSsWbM0duxYTZgwQUuWLFFOTo5mz54tyVxiycvL0wsvvCBJWrhwofr376/hw4erurpaS5cu1bJly7Rs2bLWfSUAAKBTanYY+c53vqMjR47o4YcfVn5+vkaMGKE333xT/fr1kyTl5+cHrDlSXV2te+65R3l5eYqKitLw4cP1xhtvaPr06a33KgAAQKflchzHsV3E6Xg8HsXFxam0tJTxIwAAdBJn+vnNvWkAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFUtWg6+q/jXJ/n6OK9U52ckaky/Hop2B/XbAQCAFUH96fvK1oP616cFenLVFwoNcWlE7zhdkJGg8RkJGts/QXFR4bZLBACgywvqMHL1yFR1c4dqQ3axDpQc17bco9qWe1R/XrtXLpc0LDVW4zMSdH5GosZnJCghOsJ2yQAAdDkselYr7+hxfbT3iDZkF+uj7GJlF1U0Oubs5O46PyNR5w8wvSdJMZFtUgsAAF3BmX5+E0ZO4pCnsjaYHNFHe4u1p7C80TEDekabnpMBpvckLT6qXWoDAKAzIIy0siPlVdq4r1gf7jU9J7sKPPryO9enR1R9z8kFGYlKT4iSy+WyUi8AALYRRtpY6bEabdxnek42ZBfrk4Me+fyBb2VKbGR9r8n4jASd1SuacAIACBqEkXZWXuXVpn3F9WNOth84qhpf4Fvbs7tb59fO1jl/QILOTopRSAjhBADQNRFGLDte7dPWnBJ9mF2sj/Ye0dbco6r2+gOOie8WrnH9EzS2Xw+N6ttD5/SOU1REqKWKAQBoXYSRDqbK69O23FJ9tPeIPsou1ub9JTpe4ws4JizEpaGpsRrVN9480nuoX2I3Lu0AADolwkgHV+Pz6+O8Um3MLtaWnBJtyTmqw2VVjY5LiI7QqPTacNK3h0amx6s7K8UCADoBwkgn4ziODpZWamtOibbsP6qtuSX6NM+jal/gpR2XSxqcHFPfczK6X7wG9OzO2BMAQIdDGOkCqrw+7Tjo0daco9qSU6KtOUeVd/R4o+NiIsN0XrrpORndN17npccrvhurxQIA7CKMdFGFnkptzW0IJ9sPHFVljb/RcQN6Rdf3nIxK76Gzk7srLJSbNAMA2g9hJEjU+PzaXVCmrbXhZGvu0SaXsu8WEapz+8RpdF8zc2dU33j17O62UDEAIFgQRoJYcUW1snJrw0nOUWXlHlV5lbfRcekJURrdt4f6JUYrMTpCPaIjzNduEUrsbr5GhNGbAgBoGcII6vn8jj4vLD+h96REewrLGy1n35QYd5h6REcooalHN/O1PsRERyg2MoypyAAASYQRnIanskbbco9qW+5R5ZdWquRYtY6UV6vkWLWKK6pVcqym0fL2ZyIsxBXQw5LQvSG0NPWg9wUAui7CCL4Sv9+Rp7JGxRXVgY9j1Sour/1aUa2Simodqf1aUe07/Q9uQlpcpMb2T9C4/j00tn+CBiezTD4AdAWEEbS7yhpfox6Wkz3q9jfV+RITGaax/UwwGZ+RoHN6xykynGXyAaCzIYygw/P7HZUer9HOAo827SvRxn3F2rK/pFEPS0RoiM7tE1cbTnpoTN8ExXULt1Q1AOBMEUbQKXl9fu0qKNPGfcXauK9YG7JLVFQeuEx+3Sq0Y/v30Lj+CRrXP0Fp8VGWKgYAnAxhBF2C4zjaf+SYNu4rru892dvEOiq946M0tnbMyfj+CRqUxBL5AGAbYQRdVlF5VX0w2bSvWJ8c9DSa+RMbGVY7KNYMjD2nT5zcYYw7AYD2RBhB0DhW7dXWnKP1vSdbckp07MvjTsJCdF6f+PpLO6P79VBcFONOAKAtEUYQtGp8fu3M92jjvhJtzC7Wpv3FKiqvDjimbtzJuP4JOn9AgiYN6kU4AYBWRhgBajmOo31HjmljthkUu2l/SaP794SFuDQ+I0FThiZrytBk9U3sZqlaAOg6CCPAKRSWVWrzvhJt2FesdXuKtKewPGD/2cndNWVosiYPTdZ56fEKZTAsADQbYQRohn1FFXp75yG9s7NQG/YVBwyI7dk9QpcPSdLkocmaNKinukWEWawUADoPwgjQQqXHarT6s0K9vbNQq3cVquyEOx5HhIXoorMSNWVYsiYPSVZKXKTFSgGgYyOMAK2g2uvXxn3FenvnIb2985Byi48H7D+nd5wZZzIsScNSY7ljMQCcgDACtDLHcfTZofL6YJKVe1Qn/utJi4vU5KHJmjIsWRcMSGBdEwBBjzACtLHDZVVatatQK3ce0nt7Dquyxl+/LzoiVBef3UtThibrsiFJSoiOsFgpANhBGAHaUWWNTx98UaSVOwr1zs5DKixruJ9OiEsa069H/eycs3pFczkHQFAgjACW+P2OPjlYqrd3HNLKnYXame8J2J/RM1qThyRpyrBkje3XQ2GhIZYqBYC2RRgBOogDJcf07q5CrdxxSB/uPaIaX8M/ubiocE0c2FPd3WFyuczKsJLLfC/VfjXbIbW9KSe21R/jcqn21Mb76rZrj/ny+SEhLqXFR2pgrxidlRTN1GUArYYwAnRAZZU1em9Pkd7ecUjv7i7U0WM1tktqpHd8lM5K6q6zekVrYFJ3DezVXQOTuiuxu9t2aQA6GcII0MF5fX5tyTmqLTkl8vkdOY4jx5EcqfZr7bbjNG47YVv1202fL0n++n2Bx0iOanyOcoqP6YvCch2pqG66WEk9uoXrrNpgMjCpu86qDSq946MUwgq1AJpAGAHQbCUV1fr8cLm+KCzX54Xl+vyw+Zp39LhO9psiMjxEA3qeEFJqA0v/nt2Y3gwEOcIIgFZzvNqnvUUmmHxRWK4vDlfo88JyZRdVqNrnb/Kc0BCX+iZ001m9out7Uep6VGIjuUMyEAwIIwDanNfnV27JcdOTUtuLUhdYTlxG/8uSYtwBPSnJsZGKiQxTtDtM3d1hiok0X7tFhDINGujECCMArHEcR4fLquov9ZwYVg55qk7/A2q5XFL3iDB1byKoNLV9qn3usBCCDdDOzvTzmzl8AFqdy+VSUmykkmIjdeHAngH7PJU12lt7mefzwnJ9cbhcJRXVKq/yqqzSq/Iq8zCDeqWyKu8pe1nOVHioS93dtcEmIjCoRISFyHHMQN+65/U7Tu22CVd+x5HPafje75d8jlO7rfpByHXf1w0aNuc5Tf58c5xZGC82KlxxUeGKjQwzX+u3a79GhQW2dQtX94iwDjd42O93VFHtlafSq7LKGnmO136trFFZpVee4zUB+zyVNSqv8sodFqKYSPPaYiLNa42NNH9Ops28BzF1+yPDFRHGGj1dRYvCyKJFi/Tb3/5W+fn5Gj58uBYuXKhJkyad9Pg1a9YoMzNTn376qdLS0vTjH/9Ys2fPbnHRADqv2MhwnZcer/PS4096jOM4qvL6G8LJCSGlvKqmdttX/31ZlVcVVQ3HltV+rajyqqLaJ0mq8TkqOVajkg44nVpSwKq9ZyrEpfoP6YDgUhtWTgw2TYWbpgYY1/j8J4SGhgBRVmmCQ12YaDpcmGDhb6f+dndYiGKjTDgxQcaElPrQ4g6r339iyKk7Psbd8cJcsGp2GHnppZc0d+5cLVq0SBdddJH+/Oc/a9q0adqxY4f69u3b6Pjs7GxNnz5dt912m5YuXar3339ft99+u3r16qWZM2e2yosA0LW4XC5FhocqMjxUvWK+2vomvtr/qdeFk7ITw03t12qfX6GuhsXlQkNcCqldKC7ge5dLISHmmIaHWTiuqe/Nz6z9PiTw+5Da5wsNccnrc2o/6BtCQOlx8+FeWvthX3o8sK3K65ffUX17ro6f/s34ksjwEMVGhivaHWbem0qvjtf4vtL7XSc81FUbDOp6OGpDgru2l+eEcBDtDlO1199k+Clr1MNi/swkqcrr1+GyKh1uQZCTGi4DxkSGqVvtpTx3WIgiwkLkDgs12+Gh9e3usFC5w0MUERoid/gJx5xwXMSJx4aFKPKE4078uYSgQM0eM3L++edr9OjReuqpp+rbhg4dquuuu04LFixodPx9992nFStWaOfOnfVts2fP1rZt27R+/fozek7GjABAoMoaX32AKa0NMJ4vB5hjNfX76r8eq1FZlfekU7XrREeE1geIwEsngT0MdYEj5oReidjI8DYdo+PzOyo/sXcmIMQ09NQ03uet79Wp9jY9C6y9hIe6AsJMWGhIbWCtDcRNhOOA0FsbhgPOOWVw/lJQrg3Hoa6Gc745po9G9I5r1dfZJmNGqqurtXnzZt1///0B7VOnTtUHH3zQ5Dnr16/X1KlTA9quvPJKPfPMM6qpqVF4OFP8AKC56nqOkmKaf67f76isylsfXCqqvIp2N4SJ7u6wDn3PpNAQl+K6mUtRLVVZ42vodan06ni1T1Ven6q8flV7/ary+s12zQnfe/2qqvGr2td0e5Pn1+6r9PoCAmCNz1GNz6vylnXqtIkx/Xq0ehg5U80KI0VFRfL5fEpOTg5oT05OVkFBQZPnFBQUNHm81+tVUVGRUlNTG51TVVWlqqqGPyGPx9PoGABAy4SEuBRXO4Yk3XYxlrTWZcAz5TiOvH6nNpz4VO3zBwSaGp+57Ob3n37As1M7KLrueH8T39cPrvYHDrz2+etWZP7S946jQcnd2+W9aEqLBrB+uevNcZxTdsc1dXxT7XUWLFighx56qCWlAQDQ4bhcLoWHuhQeGqLubiayflmz+uF69uyp0NDQRr0ghYWFjXo/6qSkpDR5fFhYmBITE5s8Z/78+SotLa1/5ObmNqdMAADQiTQrjERERGjMmDFauXJlQPvKlSt14YUXNnnOhAkTGh3/1ltvaezYsScdL+J2uxUbGxvwAAAAXVOzRyhlZmbqL3/5i5599lnt3LlT8+bNU05OTv26IfPnz9eNN95Yf/zs2bO1f/9+ZWZmaufOnXr22Wf1zDPP6J577mm9VwEAADqtZl+4+s53vqMjR47o4YcfVn5+vkaMGKE333xT/fr1kyTl5+crJyen/viMjAy9+eabmjdvnp588kmlpaXp8ccfZ40RAAAgiXvTAACANnKmn98ddyI5AAAICoQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFZ1ilsH1q3L5vF4LFcCAADOVN3n9unWV+0UYaSsrEySlJ6ebrkSAADQXGVlZYqLizvp/k6xHLzf79fBgwcVExMjl8vVaj/X4/EoPT1dubm5QbvMfLC/B8H++iXeA15/cL9+ifegLV+/4zgqKytTWlqaQkJOPjKkU/SMhISEqE+fPm3282NjY4PyL+CJgv09CPbXL/Ee8PqD+/VLvAdt9fpP1SNShwGsAADAKsIIAACwKqjDiNvt1s9+9jO53W7bpVgT7O9BsL9+ifeA1x/cr1/iPegIr79TDGAFAABdV1D3jAAAAPsIIwAAwCrCCAAAsIowAgAArArqMLJo0SJlZGQoMjJSY8aM0XvvvWe7pHaxYMECjRs3TjExMUpKStJ1112n3bt32y7LmgULFsjlcmnu3Lm2S2lXeXl5uuGGG5SYmKhu3brpvPPO0+bNm22X1W68Xq8efPBBZWRkKCoqSgMGDNDDDz8sv99vu7Q2sXbtWs2YMUNpaWlyuVx65ZVXAvY7jqOf//znSktLU1RUlC699FJ9+umndoptI6d6D2pqanTffffpnHPOUXR0tNLS0nTjjTfq4MGD9gpuZaf7O3CiH/zgB3K5XFq4cGG71Ba0YeSll17S3Llz9cADD2jr1q2aNGmSpk2bppycHNultbk1a9Zozpw5+vDDD7Vy5Up5vV5NnTpVFRUVtktrdxs3btSSJUt07rnn2i6lXZWUlOiiiy5SeHi4/vnPf2rHjh36/e9/r/j4eNultZtHH31Uixcv1hNPPKGdO3fqN7/5jX7729/qT3/6k+3S2kRFRYVGjhypJ554osn9v/nNb/TYY4/piSee0MaNG5WSkqIrrrii/t5gXcGp3oNjx45py5Yt+ulPf6otW7Zo+fLl+uyzz3TNNddYqLRtnO7vQJ1XXnlFH330kdLS0tqpMklOkBo/frwze/bsgLYhQ4Y4999/v6WK7CksLHQkOWvWrLFdSrsqKytzBg0a5KxcudK55JJLnLvvvtt2Se3mvvvucyZOnGi7DKuuuuoq55Zbbglo+8Y3vuHccMMNlipqP5Kcl19+uX7b7/c7KSkpzq9//ev6tsrKSicuLs5ZvHixhQrb3pffg6Zs2LDBkeTs37+/fYpqRyd7/QcOHHB69+7tfPLJJ06/fv2cP/zhD+1ST1D2jFRXV2vz5s2aOnVqQPvUqVP1wQcfWKrKntLSUklSQkKC5Ura15w5c3TVVVdpypQptktpdytWrNDYsWP1rW99S0lJSRo1apSefvpp22W1q4kTJ+qdd97RZ599Jknatm2b1q1bp+nTp1uurP1lZ2eroKAg4Hei2+3WJZdcEpS/E+uUlpbK5XIFTY+h3+/XrFmzdO+992r48OHt+tyd4kZ5ra2oqEg+n0/JyckB7cnJySooKLBUlR2O4ygzM1MTJ07UiBEjbJfTbv7+979r8+bN2rRpk+1SrNi7d6+eeuopZWZm6ic/+Yk2bNigu+66S263WzfeeKPt8trFfffdp9LSUg0ZMkShoaHy+Xz61a9+pe9+97u2S2t3db/3mvqduH//fhslWVdZWan7779f3/ve94Lm5nmPPvqowsLCdNddd7X7cwdlGKnjcrkCth3HadTW1d1xxx3avn271q1bZ7uUdpObm6u7775bb731liIjI22XY4Xf79fYsWP1yCOPSJJGjRqlTz/9VE899VTQhJGXXnpJS5cu1Ysvvqjhw4crKytLc+fOVVpamm666Sbb5VnB70SjpqZG119/vfx+vxYtWmS7nHaxefNm/fGPf9SWLVus/JkH5WWanj17KjQ0tFEvSGFhYaP/GXRld955p1asWKFVq1apT58+tstpN5s3b1ZhYaHGjBmjsLAwhYWFac2aNXr88ccVFhYmn89nu8Q2l5qaqmHDhgW0DR06NCgGcNe59957df/99+v666/XOeeco1mzZmnevHlasGCB7dLaXUpKiiQF/e9EyQSRb3/728rOztbKlSuDplfkvffeU2Fhofr27Vv/e3H//v360Y9+pP79+7f58wdlGImIiNCYMWO0cuXKgPaVK1fqwgsvtFRV+3EcR3fccYeWL1+ud999VxkZGbZLaleTJ0/Wxx9/rKysrPrH2LFj9R//8R/KyspSaGio7RLb3EUXXdRoOvdnn32mfv36Waqo/R07dkwhIYG/AkNDQ7vs1N5TycjIUEpKSsDvxOrqaq1ZsyYofifWqQsie/bs0dtvv63ExETbJbWbWbNmafv27QG/F9PS0nTvvffq3//+d5s/f9BepsnMzNSsWbM0duxYTZgwQUuWLFFOTo5mz55tu7Q2N2fOHL344ot69dVXFRMTU/+/obi4OEVFRVmuru3FxMQ0Gh8THR2txMTEoBk3M2/ePF144YV65JFH9O1vf1sbNmzQkiVLtGTJEtultZsZM2boV7/6lfr27avhw4dr69ateuyxx3TLLbfYLq1NlJeX6/PPP6/fzs7OVlZWlhISEtS3b1/NnTtXjzzyiAYNGqRBgwbpkUceUbdu3fS9733PYtWt61TvQVpamr75zW9qy5Ytev311+Xz+ep/NyYkJCgiIsJW2a3mdH8Hvhy+wsPDlZKSosGDB7d9ce0yZ6eDevLJJ51+/fo5ERERzujRo4NmaqukJh/PPfec7dKsCbapvY7jOK+99pozYsQIx+12O0OGDHGWLFliu6R25fF4nLvvvtvp27evExkZ6QwYMMB54IEHnKqqKtultYlVq1Y1+e/+pptuchzHTO/92c9+5qSkpDhut9u5+OKLnY8//thu0a3sVO9Bdnb2SX83rlq1ynbpreJ0fwe+rD2n9rocx3HaPvIAAAA0LSjHjAAAgI6DMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMCq/w+qAZGc/Pt/nAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(all_avg_train_loss)\n",
        "plt.plot(all_avg_test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model RuBert-Large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'ruRoberta-large'...\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/sberbank-ai/ruRoberta-large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/ruRoberta-large\")\n",
        "\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"sberbank-ai/ruRoberta-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d:\\New folder\\New folder\\DSnML_Innopolis2022\\00_Final_Attestation\\ruRoberta-large/\n"
          ]
        }
      ],
      "source": [
        "model_path = os.path.join(base_path, 'ruRoberta-large/')\n",
        "print(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'l2i' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7608\\3824650115.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconfig_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'config.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_json_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml2i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moutput_model_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pytorch_model.bin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'l2i' is not defined"
          ]
        }
      ],
      "source": [
        "config_path = os.path.join(base_path, model_path, 'config.json')\n",
        "conf = BertConfig.from_json_file(config_path)\n",
        "conf.num_labels = len(l2i)\n",
        "\n",
        "output_model_file = os.path.join(base_path, model_path, 'pytorch_model.bin')\n",
        "\n",
        "model = BertModel(conf)\n",
        "\n",
        "model.load_state_dict(torch.load(output_model_file), strict=False)\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RobertaForMaskedLM(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 1024)\n",
            "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (12): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (13): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (14): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (15): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (16): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (17): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (18): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (19): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (20): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (21): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (22): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (23): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lm_head): RobertaLMHead(\n",
            "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (decoder): Linear(in_features=1024, out_features=50265, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "sample() missing 1 required positional argument: 'input_ids'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7608\\1709407715.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m: sample() missing 1 required positional argument: 'input_ids'"
          ]
        }
      ],
      "source": [
        "model.sample()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Pytorch_seq2seq_with_attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "846dd53c5a100503afcb3f5301bb10f61481596a80ae839ecd432be859b5d4d0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
