{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in c:\\users\\leysh\\anaconda3\\lib\\site-packages (4.23.1)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from transformers) (0.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n","Requirement already satisfied: requests in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n","Requirement already satisfied: filelock in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: colorama in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: nlp in c:\\users\\leysh\\anaconda3\\lib\\site-packages (0.4.0)\n","Requirement already satisfied: filelock in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from nlp) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from nlp) (4.64.1)\n","Requirement already satisfied: xxhash in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from nlp) (3.1.0)\n","Requirement already satisfied: pyarrow>=0.16.0 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from nlp) (9.0.0)\n","Requirement already satisfied: numpy in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from nlp) (1.21.5)\n","Requirement already satisfied: dill in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from nlp) (0.3.5.1)\n","Requirement already satisfied: pandas in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from nlp) (1.4.4)\n","Requirement already satisfied: requests>=2.19.0 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from nlp) (2.28.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (1.26.11)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (3.3)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (2022.9.14)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (2.0.4)\n","Requirement already satisfied: colorama in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from tqdm>=4.27->nlp) (0.4.5)\n","Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from pandas->nlp) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from pandas->nlp) (2022.1)\n","Requirement already satisfied: six>=1.5 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->nlp) (1.16.0)\n"]}],"source":["!pip install --upgrade transformers\n","!pip install nlp"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: fastai==1.0.61 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (1.0.61)\n","Requirement already satisfied: packaging in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (21.3)\n","Requirement already satisfied: torch>=1.0.0 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (1.12.1)\n","Requirement already satisfied: bottleneck in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (1.3.5)\n","Requirement already satisfied: Pillow in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (9.2.0)\n","Requirement already satisfied: matplotlib in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (3.5.2)\n","Requirement already satisfied: numpy>=1.15 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (1.21.5)\n","Requirement already satisfied: torchvision in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (0.13.1)\n","Requirement already satisfied: requests in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (2.28.1)\n","Requirement already satisfied: scipy in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (1.9.1)\n","Requirement already satisfied: beautifulsoup4 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (4.11.1)\n","Requirement already satisfied: numexpr in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (2.8.3)\n","Requirement already satisfied: fastprogress>=0.2.1 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (1.0.3)\n","Requirement already satisfied: nvidia-ml-py3 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (7.352.0)\n","Requirement already satisfied: pandas in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (1.4.4)\n","Requirement already satisfied: pyyaml in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from fastai==1.0.61) (6.0)\n","Requirement already satisfied: typing_extensions in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from torch>=1.0.0->fastai==1.0.61) (4.3.0)\n","Requirement already satisfied: soupsieve>1.2 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from beautifulsoup4->fastai==1.0.61) (2.3.1)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from matplotlib->fastai==1.0.61) (4.25.0)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from matplotlib->fastai==1.0.61) (2.8.2)\n","Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from matplotlib->fastai==1.0.61) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from matplotlib->fastai==1.0.61) (1.4.2)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from matplotlib->fastai==1.0.61) (0.11.0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from pandas->fastai==1.0.61) (2022.1)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from requests->fastai==1.0.61) (2.0.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from requests->fastai==1.0.61) (1.26.11)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from requests->fastai==1.0.61) (3.3)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from requests->fastai==1.0.61) (2022.9.14)\n","Requirement already satisfied: six>=1.5 in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->fastai==1.0.61) (1.16.0)\n","Requirement already satisfied: biopython in c:\\users\\leysh\\anaconda3\\lib\\site-packages (1.79)\n","Requirement already satisfied: numpy in c:\\users\\leysh\\anaconda3\\lib\\site-packages (from biopython) (1.21.5)\n"]}],"source":["!pip install fastai==1.0.61\n","!pip install biopython"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install "]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","\n","import transformers\n","from transformers import RobertaTokenizer\n","from transformers import RobertaForSequenceClassification"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import nlp"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"ename":"UnsupportedOperation","evalue":"fileno","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21436\\3935612481.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfastai\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\fastai\\text\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbasics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\fastai\\text\\learner.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGradientClipping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\fastai\\text\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mawd_lstm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mawd_lstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__all__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__all__\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\fastai\\text\\models\\awd_lstm.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[0mbasic_train\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[0mbasic_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextClasDataBunch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\fastai\\text\\data.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"NLP data loading pipeline. Supports csv, folders, and preprocessed data.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorch_core\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_block\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\fastai\\text\\transform.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorch_core\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbols\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mORTH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# These are imported as part of the API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprefer_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_cpu\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\thinc\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mabout\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\thinc\\config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelMetaclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelField\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwasabi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msrsly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcatalogue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\wasabi\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mabout\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPrinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\wasabi\\printer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pretty, no_print, colors, icons, line_max, animation, animation_ascii, hide_animation, ignore_warnings, env_prefix, timestamp)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpretty\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0menv_no_pretty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_print\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mno_print\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_color\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msupports_ansi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0menv_log_friendly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhide_animation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhide_animation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0menv_log_friendly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_warnings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mignore_warnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\wasabi\\util.py\u001b[0m in \u001b[0;36msupports_ansi\u001b[1;34m()\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"ANSICON\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_windows_console_supports_ansi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\wasabi\\util.py\u001b[0m in \u001b[0;36m_windows_console_supports_ansi\u001b[1;34m()\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m     \u001b[0mconsole\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsvcrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_osfhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;31m# Try to enable ANSI output support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\leysh\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mfileno\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_stdstream_copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fileno\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_watch_pipe_fd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mUnsupportedOperation\u001b[0m: fileno"]}],"source":["import fastai\n","from fastai.text import *\n","from fastai.metrics import *"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["transformers version:  4.23.1\n","fast.ai version:  2.7.9\n"]}],"source":["print(\"transformers version: \", transformers.__version__)\n","print(\"fast.ai version: \", fastai.__version__)"]},{"cell_type":"markdown","metadata":{},"source":["##### FastAI wrapper methods around Roberta Tokenizer "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Creating a config object to store task specific information\n","class Config(dict):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        for k, v in kwargs.items():\n","            setattr(self, k, v)\n","    \n","    def set(self, key, val):\n","        self[key] = val\n","        setattr(self, key, val)\n","        \n","config = Config(\n","    task = \"news\",\n","    testing=False,\n","    seed = 2019,\n","    roberta_model_name='roberta-large', # can also be exchanged with roberta-base \n","    max_lr=1e-5,\n","    epochs=4,\n","    use_fp16=False,\n","    bs=4, \n","    max_seq_len=512, \n","    num_labels = 2,\n","    hidden_dropout_prob=.05,\n","    hidden_size=768, # 1024 for roberta-large\n","    start_tok = \"<s>\",\n","    end_tok = \"</s>\",\n","    mark_fields=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'BaseTokenizer' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21344\\1627505419.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mFastAiRobertaTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseTokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pretrained_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'BaseTokenizer' is not defined"]}],"source":["class FastAiRobertaTokenizer(BaseTokenizer):\n","    def __init__(self, tokenizer: RobertaTokenizer, max_seq_len: int=128, **kwargs): \n","        self._pretrained_tokenizer = tokenizer\n","        self.max_seq_len = max_seq_len \n","    def __call__(self, *args, **kwargs): \n","        return self \n","    def tokenizer(self, t:str) -> List[str]: \n","        return [\"<s>\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"</s>\"]\n","    \n","    \n","class RobertaTokenizeProcessor(TokenizeProcessor):\n","    def __init__(self, tokenizer):\n","        super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n","         \n","class RobertaNumericalizeProcessor(NumericalizeProcessor):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, vocab=fastai_vocab, **kwargs)\n","        \n","def get_roberta_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n","    return [RobertaTokenizeProcessor(tokenizer=tokenizer), NumericalizeProcessor(vocab=vocab)]\n","\n","\n","class RobertaDataBunch(TextDataBunch):\n","    @classmethod\n","    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=64, val_bs:int=None, pad_idx=1,\n","               pad_first=True, device:torch.device=None, no_check:bool=False, backwards:bool=False, \n","               dl_tfms:Optional[Collection[Callable]]=None, **dl_kwargs) -> DataBunch:\n","        \n","        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n","        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n","        val_bs = ifnone(val_bs, bs)\n","        collate_fn = partial(pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n","        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs)\n","        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n","        dataloaders = [train_dl]\n","        for ds in datasets[1:]:\n","            lengths = [len(t) for t in ds.x.items]\n","            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n","            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n","        return cls(*dataloaders, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)\n","    \n","\n","class RobertaTextList(TextList):\n","    _bunch = RobertaDataBunch\n","    _label_cls = TextList"]},{"cell_type":"markdown","metadata":{},"source":["###### Load the news data (boolq)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = nlp.load_dataset('boolq')\n","\n","''' Prepare pandas DF'''\n","feat_cols = \"review\"\n","label_cols = \"answer\"\n","\n","train_data = pd.DataFrame(dataset[\"train\"])\n","test_data = pd.DataFrame(dataset[\"validation\"])\n","\n","\n","train_data[\"review\"] = train_data[\"passage\"] + \" </s> </s> \" + train_data[\"question\"]\n","test_data[\"review\"] = test_data[\"passage\"] + \" </s> </s> \" + test_data[\"question\"]\n","\n","train_data[label_cols] = train_data[label_cols].astype(int)\n","test_data[label_cols] = test_data[label_cols].astype(int)\n","\n","combined_df = pd.concat([train_data, test_data])\n","\n","X_train, X_val, y_train, y_val = train_test_split(combined_df[feat_cols], combined_df[label_cols], \\\n","                                                  test_size=0.2, random_state=101)\n","\n","train_data = pd.concat([X_train, y_train], axis = 1)\n","val_data = pd.concat([X_val, y_val], axis = 1)\n","\n","X_train, X_val, y_train, y_val = train_test_split(val_data[feat_cols], val_data[label_cols], \\\n","                                                  test_size=0.5, random_state=10)\n","\n","val_data = pd.concat([X_train, y_train], axis = 1)\n","test_data = pd.concat([X_val, y_val], axis = 1)\n","\n","\n","print(\"train shape: \", len(train_data))\n","print(\"val shape: \", len(val_data))\n","print(\"test shape: \", len(test_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data.iloc[1][\"review\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["''' Initialize Roberta tokenizer'''\n","roberta_tok = RobertaTokenizer.from_pretrained(config.roberta_model_name)\n","\n","fastai_tokenizer = Tokenizer(tok_func = FastAiRobertaTokenizer(roberta_tok, \\\n","                                                               max_seq_len=config.max_seq_len), \\\n","                             pre_rules=[], post_rules=[])\n","\n","''' Construct fast.ai vocab using RobertaTokenizer dictionary'''\n","path = Path()\n","roberta_tok.save_vocabulary(path)\n","with open('vocab.json', 'r') as f:\n","    roberta_vocab_dict = json.load(f)\n","    \n","fastai_roberta_vocab = Vocab(list(roberta_vocab_dict.keys()))\n","print(\"Roberta dict size: \", len(roberta_vocab_dict.keys()))\n","\n","\n","print(\"Batch size is : \", config.bs)\n","# loading the tokenizer and vocab processors\n","processor = get_roberta_processor(tokenizer=fastai_tokenizer, vocab=fastai_roberta_vocab)\n","\n","# creating our databunch \n","data = ItemLists(\".\", RobertaTextList.from_df(train_data, \".\", cols=feat_cols, processor=processor),\n","                      RobertaTextList.from_df(val_data, \".\", cols=feat_cols, processor=processor)\n","                ) \\\n","       .label_from_df(cols=label_cols, label_cls=CategoryList) \\\n","       .add_test(RobertaTextList.from_df(test_data, \".\", cols=feat_cols, processor=processor)) \\\n","       .databunch(bs=config.bs,pad_first=False)"]},{"cell_type":"markdown","metadata":{},"source":["###### Model training "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# defining our model architecture \n","class RobertaForSequenceClassificationModel(nn.Module):\n","    def __init__(self,num_labels=config.num_labels):\n","        super(RobertaForSequenceClassificationModel,self).__init__()\n","        self.num_labels = num_labels\n","        self.roberta = RobertaForSequenceClassification.from_pretrained(config.roberta_model_name,num_labels= self.num_labels)\n","\n","    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n","        outputs = self.roberta(input_ids, token_type_ids, attention_mask)\n","        logits = outputs[0] \n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["roberta_model = RobertaForSequenceClassificationModel(config.num_labels) \n","learn = Learner(data, roberta_model, metrics=[accuracy])\n","learn.model.roberta.train() # setting roberta to train as it is in eval mode by default"]},{"cell_type":"markdown","metadata":{},"source":["###### Plot the LR against loss"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["learn.lr_find()\n","learn.recorder.plot()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Cuda available: \", torch.cuda.is_available())\n","# Looks like 2 epochs are enough on Large transformers\n","learn.fit_one_cycle(3, max_lr=1e-5)"]},{"cell_type":"markdown","metadata":{},"source":["###### Inference on Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_preds_as_nparray(ds_type, p_learn) -> np.ndarray:\n","    p_learn.model.roberta.eval()\n","    preds = p_learn.get_preds(ds_type)[0].detach().cpu().numpy()\n","    \n","    sampler = [i for i in data.dl(ds_type).sampler]\n","    reverse_sampler = np.argsort(sampler)\n","    ordered_preds = preds[reverse_sampler, :]\n","    pred_values = np.argmax(ordered_preds, axis=1)\n","    return ordered_preds, pred_values"]},{"cell_type":"markdown","metadata":{},"source":["###### Predict validation accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# val preds\n","preds, pred_values = get_preds_as_nparray(DatasetType.Valid, learn)\n","acc = (pred_values == data.valid_ds.y.items).mean()\n","print(\"Validation accuracy: \", acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_samples = 0\n","for idx, row in val_data.reset_index(drop=True).iterrows():\n","    if num_samples < 60:\n","        print(row[\"review\"])\n","        print(\"Ground truth: \", row[\"answer\"])\n","        print(\"Prediction: \", pred_values[idx])\n","        print(\"\\n\\n\")\n","        num_samples += 1\n","    else:\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["###### Save the model "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["learn.save(\"roberta_large_tuned_boolq_model\")"]},{"cell_type":"markdown","metadata":{},"source":["###### Load the saved model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = RobertaForSequenceClassificationModel(config.num_labels) \n","new_learner = Learner(data, model, metrics=[accuracy])\n","new_learner.model.roberta.eval()\n","new_learner.load(\"roberta_large_tuned_boolq_model\")\n","\n","preds, pred_values = get_preds_as_nparray(DatasetType.Valid, new_learner)\n","(pred_values == data.valid_ds.y.items).mean()"]},{"cell_type":"markdown","metadata":{},"source":["###### Some examples "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class_map = {0: \"False\", 1: \"True\"}\n","l_str = \"\"\"<s> Reliance is charged with criminal offence due to insider trading </s> </s> \n","is reliance not charged with some offence </s>\"\"\"\n","print(\"prediction: \", class_map[torch.argmax(new_learner.predict(l_str)[2]).item()])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["l_str = \"\"\"<s> Reliance is charged with criminal offence due to insider trading </s> </s> \n","is reliance charged with some offence </s>\"\"\"\n","print(\"prediction: \", class_map[torch.argmax(new_learner.predict(l_str)[2]).item()])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["l_str = \"\"\"<s> Besides a case against Malaysian tycoon and Maxis owner T. Ananda Krishnan, \n","Maxis senior executive Ralph Marshall, former Telecom Minister Dayanidhi Maran and three companies in \n","connection with the controversial Aircel Maxis deal, India\\'s Central Bureau of Investigations (CBI) has also \n","booked Maran\\'s brother Kalanidhi, and three companies, Aspro, Maxis and Sun TV, in the case on charges of \n","criminal conspiracy under IPC and Prevention of Corruption Act. CBI has registered a case against Maran brothers, Ralph Marshall and T Anandkrishnan and \n","three companies under section 120b of IPC read with 13(2) with 13 (1)(d) and also section 7 and 12 of the \n","Prevention of Corruption Act. </s> </s>\n","is Sun Tv not committed any offence like corruption </s>\n","\"\"\"\n","print(\"probs: \", new_learner.predict(l_str)[2])\n","print(\"prediction: \", class_map[torch.argmax(new_learner.predict(l_str)[2]).item()])"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["l_str = \"\"\" <s> mBanks compliance policy has a special focus on the following issues: prevention of money laundering \n","and terrorist financing; appropriate handling of confidential information; \n","protection of personal data; supervision of legal compliance in the brokerage and custody business; \n","avoidance of conflicts of interest; compliance with rules of giving and accepting gifts by Bank executive \n","officers and employees; verification of legal compliance under outsourcing agreements signed by the Bank; \n","obligatory publication and reporting to relevant regulators on events in the operation of the Bank; \n","advisory to organisational units of the Bank on compliance with new and existing legislation and \n","market standards. </s> </s>\n","is mBank committed any crime like terrorist financing </s>\n","\"\"\"\n","print(\"prediction: \", class_map[torch.argmax(new_learner.predict(l_str)[2]).item()])\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["l_str = \"\"\" <s> In 2009, Japanese regulators again took action against Citibank Japan, \n","because the Bank of Nova Scotia (Scotiabank) had not set up an effective money laundering \n","monitoring system. </s> </s>\n","is Scotiabank committed any offence </s>\n","\"\"\"\n","print(\"prediction: \", class_map[torch.argmax(new_learner.predict(l_str)[2]).item()])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"846dd53c5a100503afcb3f5301bb10f61481596a80ae839ecd432be859b5d4d0"}}},"nbformat":4,"nbformat_minor":4}
