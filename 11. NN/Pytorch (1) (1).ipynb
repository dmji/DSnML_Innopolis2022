{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq_ozig-JDez"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRQ2x9UuKnh7",
        "outputId": "fdde8884-3a25-42f1-d97d-8df2efd5e903"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c5-q9YhK_CR"
      },
      "source": [
        "1. Подготовка данных\n",
        "2. Создание модели\n",
        "3. Обучение модели\n",
        "4. Проверка модели\n",
        "5. Применение модели на новых данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1yoaGFgKvbw"
      },
      "source": [
        "# Подготовка данных\n",
        "from torch.utils.data import Dataset, Dataset, random_split\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrDzUD92MP7V"
      },
      "source": [
        "class CSVLoader(Dataset):\n",
        "\n",
        "  def __init__(self,path):\n",
        "    df = pd.read_csv(path, header=None)\n",
        "    self.X = df.drop('target',axis=1).values\n",
        "    self.Y = df.target.values\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return [self.X[idx],self.Y[idx]]\n",
        "\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdfWLeJwNHx4"
      },
      "source": [
        "dataset = CSVLoader(path,batch_size=10,shuffle=True,num_workers=20)\n",
        "train,test = random_split(dataset,[[..]],[[...]])\n",
        "train_dl = DataLoader(train,batch_size=32,shuffle=True)\n",
        "test_dl =  DataLoader(test,batch_size=32,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JfsI94DAKhXY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edt7qAtXO6jV"
      },
      "source": [
        "for i, (x_train,y_train) in enumerate(train_dl):\n",
        "  ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkVLqSqLPJVA"
      },
      "source": [
        "# 2Создание модели\n",
        "from torch.nn import Module\n",
        "class NN(Module):\n",
        "\n",
        "  def __init__(self,n_inputs):\n",
        "    super(NN,self).__init__()\n",
        "    self.layer = Linear(n_inputs,1)\n",
        "    self.activation = Sigmoid()\n",
        "\n",
        "  def forward(self,X):\n",
        "    X = self.layer(X)\n",
        "    X = self.activation(X)\n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "tZ69memRM_0x",
        "outputId": "2e12349a-6dfd-4fe4-edc4-2ca648321806"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4334e40b90d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-fb2eb1e32dbd>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_inputs)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Linear' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPkZM32EQQsL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "b1e8388d-e0c4-4b82-96be-aee493f88668"
      },
      "source": [
        "cost = #MSELoss , CrossEntrophyLoss -multiclass , BCELoss - binary classification\n",
        "optimizer = SGD(model.parameters(),lr=0.01,momentum=0.9)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-c4033ce83ccd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    cost = #MSELoss , CrossEntrophyLoss -multiclass , BCELoss - binary classification\u001b[0m\n\u001b[0m                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2NeMp6mQysj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "57cd83db-ce88-4d2c-e7a6-7cebf1e04702"
      },
      "source": [
        "for epoch in range(10):\n",
        "  for i, (x_train,y_train) in enumerate(train_dl):\n",
        "    ...\n",
        "    optimizer.zero_grad()\n",
        "    yhat = model(x_train)\n",
        "    loss = cost(yhat,y_train)\n",
        "    loss.backward()\n",
        "    optimer.step()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-36c1c8925925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dl' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZN_yf1SRw0p"
      },
      "source": [
        "# 4 - Проверка модели\n",
        "for i, (x_test,y_test) in enumerate(test_dl):\n",
        "  yhat = model(x_test)\n",
        "  ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCl1NJIbSHLR"
      },
      "source": [
        "# 5 - Применение модели на новых данных\n",
        "row = Variable(Tensor([row]).float())\n",
        "yhat =model(row)\n",
        "yhat = yhat.detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyFPrawOS848"
      },
      "source": [
        "Обучение модели бинарной классиикации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6DW9E_6TEqM"
      },
      "source": [
        "from numpy import  vstack\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch import Tensor\n",
        "from torch.nn import Linear,ReLU, Sigmoid, Module, BCELoss\n",
        "from torch.nn.init import kaiming_uniform_, xavier_uniform_\n",
        "from torch.optim import SGD"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFYmRkRDaILT",
        "outputId": "b6daef65-7722-43b5-d337-3c9b67affce9"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv', header=None)\n",
        "#df.head()\n",
        "LabelEncoder().fit_transform(df.values[:,-1]).astype('float32')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3rqm2k3T4bi",
        "outputId": "86360fc7-81f5-40f5-b46b-64cf7032d0b7"
      },
      "source": [
        "class CSVLoader(Dataset):\n",
        "\n",
        "  def __init__(self,path):\n",
        "    super(CSVLoader,self).__init__()\n",
        "    df = pd.read_csv(path, header=None)\n",
        "    self.X = df.values[:,:-1].astype('float32')\n",
        "    self.Y = LabelEncoder().fit_transform(df.values[:,-1]).astype('float32')\n",
        "    self.Y = self.Y.reshape(len(self.Y),1)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return [self.X[idx],self.Y[idx]]\n",
        "\n",
        "  def get_splits(self,n_test=0.33):\n",
        "    test_size = round(n_test * len(self.X))\n",
        "    train_size = len(self.X) - test_size\n",
        "    return random_split(self,[train_size,test_size])\n",
        "\n",
        "\n",
        "\n",
        "class NN(Module):\n",
        "\n",
        "  def __init__(self,n_inputs):\n",
        "    super(NN,self).__init__()\n",
        "    self.layer = Linear(n_inputs,10)\n",
        "    kaiming_uniform_(self.layer.weight, nonlinearity='relu')\n",
        "    self.activation = ReLU()\n",
        "\n",
        "    # 2 -layer\n",
        "    self.layer2 = Linear(10,8)\n",
        "    kaiming_uniform_(self.layer2.weight, nonlinearity='relu')\n",
        "    self.activation2 = ReLU()\n",
        "\n",
        "    # 3 output layer\n",
        "    self.output = Linear(8,1)\n",
        "    xavier_uniform_(self.output.weight)\n",
        "    self.activation3 = Sigmoid()\n",
        "\n",
        "  def forward(self,X):\n",
        "    X = self.layer(X)\n",
        "    X = self.activation(X)\n",
        "    X = self.layer2(X)\n",
        "    X = self.activation2(X)\n",
        "    X = self.output(X)\n",
        "    X = self.activation3(X)\n",
        "    return X\n",
        "\n",
        "\n",
        "def prepare_dataset(path):\n",
        "  dataset = CSVLoader(path)\n",
        "  train,test = dataset.get_splits()\n",
        "  train_dl = DataLoader(train,batch_size=32,shuffle=True)\n",
        "  test_dl =  DataLoader(test,batch_size=32,shuffle=False)\n",
        "  return train_dl,test_dl\n",
        "\n",
        "def train_model(train_dl, model):\n",
        "    # define the optimization\n",
        "    cost = BCELoss()#MSELoss , CrossEntrophyLoss -multiclass , BCELoss - binary classification\n",
        "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    for epoch in range(100):\n",
        "        for i, (x_train,y_train) in enumerate(train_dl):\n",
        "            optimizer.zero_grad()\n",
        "            yhat = model(x_train)\n",
        "            loss = cost(yhat, y_train)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def evaluate(test_dl,model):\n",
        "  predictions, actuals = list(), list()\n",
        "\n",
        "  for i, (x_test,y_test) in enumerate(test_dl):\n",
        "    yhat = model(x_test)\n",
        "    yhat = yhat.detach().numpy().round()\n",
        "    actual = y_test.numpy()\n",
        "    actual = actual.reshape(len(actual),1)\n",
        "    predictions.append(yhat)\n",
        "    actuals.append(actual)\n",
        "  \n",
        "  predictions, actuals = vstack(predictions), vstack(actuals)\n",
        "\n",
        "  acc = accuracy_score(actuals,  predictions)\n",
        "  return acc\n",
        "\n",
        "def predict(row,model):\n",
        "  row = Tensor([row]).float()\n",
        "  yhat = model(row)\n",
        "  yhat = yhat.detach().numpy()\n",
        "  return yhat\n",
        "\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
        "\n",
        "train_dl, test_dl = prepare_dataset(path)\n",
        "print(len(train_dl.dataset),len(test_dl.dataset))\n",
        "model = NN(34)\n",
        "train_model(train_dl,model)\n",
        "acc = evaluate(test_dl,model)\n",
        "\n",
        "print('Accuracy: {}'.format(acc))\n",
        "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
        "yhat = predict(row,model)\n",
        "\n",
        "print(yhat)\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235 116\n",
            "Accuracy: 0.9137931034482759\n",
            "[[0.9973641]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SScNaOka48r"
      },
      "source": [
        "from numpy import vstack\n",
        "from numpy import argmax\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Normalize\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Softmax\n",
        "from torch.nn import Module\n",
        "from torch.optim import SGD\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.nn.init import kaiming_uniform_\n",
        "from torch.nn.init import xavier_uniform_\n",
        " \n",
        "class CNN(Module):\n",
        "    def __init__(self, n_channels):\n",
        "        super(CNN, self).__init__()\n",
        "        # input to first hidden layer\n",
        "        self.hidden1 = Conv2d(n_channels, 32, (3,3)) # 32,26,26,32\n",
        "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
        "        self.act1 = ReLU()\n",
        "        # first pooling layer\n",
        "        self.pool1 = MaxPool2d((2,2), stride=(2,2)) #32, 13,13,32\n",
        "        # second hidden layer\n",
        "        self.hidden2 = Conv2d(32, 32, (3,3)) # 32,11,11,32\n",
        "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
        "        self.act2 = ReLU()\n",
        "        # second pooling layer\n",
        "        self.pool2 = MaxPool2d((2,2), stride=(2,2)) # 32,5,5,32\n",
        "        # fully connected layer\n",
        "        self.hidden3 = Linear(5*5*32, 100)\n",
        "        kaiming_uniform_(self.hidden3.weight, nonlinearity='relu')\n",
        "        self.act3 = ReLU()\n",
        "        # output layer\n",
        "        self.hidden4 = Linear(100, 10)\n",
        "        xavier_uniform_(self.hidden4.weight)\n",
        "        self.act4 = Softmax(dim=1)\n",
        " \n",
        "    def forward(self, X):\n",
        "        # input to first hidden layer\n",
        "        X = self.hidden1(X)\n",
        "        X = self.act1(X)\n",
        "        X = self.pool1(X)\n",
        "        # second hidden layer\n",
        "        X = self.hidden2(X)\n",
        "        X = self.act2(X)\n",
        "        X = self.pool2(X)\n",
        "        # flatten\n",
        "        X = X.view(-1, 4*4*50)\n",
        "        # third hidden layer\n",
        "        X = self.hidden3(X)\n",
        "        X = self.act3(X)\n",
        "        X = self.hidden4(X)\n",
        "        X = selact4(X)f.\n",
        "        return X\n",
        " \n",
        "def prepare_data(path):\n",
        "    trans = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
        "    train = MNIST(path, train=True, download=True, transform=trans)\n",
        "    test = MNIST(path, train=False, download=True, transform=trans)\n",
        "    train_dl = DataLoader(train, batch_size=64, shuffle=True)\n",
        "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
        "    return train_dl, test_dl\n",
        "\n",
        "def train_model(train_dl, model):\n",
        "    criterion = CrossEntropyLoss()\n",
        "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    for epoch in range(10):\n",
        "        for i, (inputs, targets) in enumerate(train_dl):\n",
        "            optimizer.zero_grad()\n",
        "            yhat = model(inputs)\n",
        "            loss = criterion(yhat, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        " \n",
        "def evaluate_model(test_dl, model):\n",
        "    predictions, actuals = list(), list()\n",
        "    for i, (inputs, targets) in enumerate(test_dl):\n",
        "        yhat = model(inputs)\n",
        "        yhat = yhat.detach().numpy()\n",
        "        actual = targets.numpy()\n",
        "        yhat = argmax(yhat, axis=1)\n",
        "        actual = actual.reshape((len(actual), 1))\n",
        "        yhat = yhat.reshape((len(yhat), 1))\n",
        "        predictions.append(yhat)\n",
        "        \n",
        "    predictions, actuals = vstack(predictions), vstackactuals.append(actual)(actuals)\n",
        "    acc = accuracy_score(actuals, predictions)\n",
        "    return acc\n",
        " \n",
        "path = '~/.torch/datasets/mnist'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for params in optimizer.state_dict():\n",
        "  print(params, optimizer.state_dict()[params].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "oJDZBaYMYzru",
        "outputId": "adbba159-d487-43d5-944c-63083575a17a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3572794ff5a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'model.pytorch')"
      ],
      "metadata": {
        "id": "SxYutE1EZKbG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(34)"
      ],
      "metadata": {
        "id": "adnmrPVyZbOc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model.pytorch'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gLk-MWtZhN4",
        "outputId": "dd55f2aa-09f2-4136-a212-47e38e08d7b8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layer): Linear(in_features=34, out_features=10, bias=True)\n",
              "  (activation): ReLU()\n",
              "  (layer2): Linear(in_features=10, out_features=8, bias=True)\n",
              "  (activation2): ReLU()\n",
              "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
              "  (activation3): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
        "yhat = predict(row,model)"
      ],
      "metadata": {
        "id": "oUistpynZniv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIL \n",
        "skimage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTzapim9Z47H",
        "outputId": "93a3f738-23ec-49dc-d353-f1f4130d79b5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9973641]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}